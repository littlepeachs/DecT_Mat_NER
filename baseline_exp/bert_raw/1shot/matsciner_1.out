Some weights of the model checkpoint at m3rg-iitd/matscibert were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
using device: cuda
5 511 546
['I-APL', 'I-CMT', 'I-DSC', 'I-MAT', 'I-PRO', 'I-SMT', 'I-SPL', 'O']
training_time:0.13003754615783691
loss:2.1194498538970947
training_time:0.05240058898925781
loss:0.6174298524856567
training_time:0.05234265327453613
loss:0.5115004777908325
training_time:0.049915313720703125
loss:0.27247872948646545
{'APL': 1.25, 'CMT': 0.0, 'DSC': 0.0, 'MAT': 0.0, 'PRO': 0.0, 'SMT': 0.0, 'SPL': 0.0, 'macro_f1': 0.0017857142857142857, 'micro_f1': 0.0008631851532153647}
training_time:0.054666757583618164
loss:0.12566423416137695
{'APL': 3.428571428571429, 'CMT': 0.0, 'DSC': 0.0, 'MAT': 1.907790143084261, 'PRO': 0.5398110661268556, 'SMT': 0.0, 'SPL': 5.555555555555556, 'macro_f1': 0.01633104027619729, 'micro_f1': 0.011035653650254669}
training_time:0.06791377067565918
loss:0.06241971254348755
{'APL': 5.405405405405405, 'CMT': 0.0, 'DSC': 0.0, 'MAT': 5.837173579109063, 'PRO': 0.801068090787717, 'SMT': 0.0, 'SPL': 10.81081081081081, 'macro_f1': 0.03264922555158999, 'micro_f1': 0.025844101709045435}
training_time:0.0722355842590332
loss:0.02232777699828148
{'APL': 9.424083769633508, 'CMT': 1.092896174863388, 'DSC': 0.0, 'MAT': 11.420204978038068, 'PRO': 0.801068090787717, 'SMT': 0.0, 'SPL': 13.157894736842104, 'macro_f1': 0.05128021107166398, 'micro_f1': 0.046702171241294554}
training_time:0.07460188865661621
loss:0.02880289778113365
{'APL': 17.51152073732719, 'CMT': 1.0752688172043012, 'DSC': 0.0, 'MAT': 23.697916666666664, 'PRO': 1.0652463382157122, 'SMT': 1.0256410256410258, 'SPL': 14.285714285714285, 'macro_f1': 0.08380186838681311, 'micro_f1': 0.09355828220858896}
training_time:0.07004904747009277
loss:0.008609914220869541
{'APL': 19.29824561403509, 'CMT': 1.0362694300518136, 'DSC': 0.4878048780487805, 'MAT': 32.44495944380069, 'PRO': 1.0638297872340425, 'SMT': 1.8779342723004695, 'SPL': 16.27906976744186, 'macro_f1': 0.10355444741844679, 'micro_f1': 0.1289617486338798}
training_time:0.07843446731567383
loss:0.010945369489490986
{'APL': 24.710424710424707, 'CMT': 0.9900990099009903, 'DSC': 1.431980906921241, 'MAT': 40.04192872117401, 'PRO': 1.3089005235602091, 'SMT': 2.1505376344086025, 'SPL': 19.35483870967742, 'macro_f1': 0.1285553003086674, 'micro_f1': 0.1643097643097643}
training_time:0.060431480407714844
loss:0.005037376191467047
{'APL': 25.087108013937282, 'CMT': 2.7649769585253456, 'DSC': 3.309692671394799, 'MAT': 43.57429718875502, 'PRO': 1.5604681404421328, 'SMT': 3.1347962382445145, 'SPL': 20.618556701030926, 'macro_f1': 0.14292842273190004, 'micro_f1': 0.18275418275418276}
training_time:0.08262348175048828
loss:0.0029784522484987974
{'APL': 23.367697594501717, 'CMT': 2.7777777777777777, 'DSC': 4.68384074941452, 'MAT': 43.51219512195122, 'PRO': 2.3136246786632393, 'SMT': 4.558404558404559, 'SPL': 21.782178217821784, 'macro_f1': 0.1471367409979069, 'micro_f1': 0.18689244277202882}
training_time:0.07163190841674805
loss:0.002086239168420434
{'APL': 23.80952380952381, 'CMT': 2.6200873362445414, 'DSC': 5.977011494252873, 'MAT': 43.7984496124031, 'PRO': 3.0848329048843186, 'SMT': 5.7894736842105265, 'SPL': 21.782178217821784, 'macro_f1': 0.1526593672276299, 'micro_f1': 0.19144352108341028}
training_time:0.05586838722229004
loss:0.0021837069652974606
{'APL': 23.728813559322035, 'CMT': 3.389830508474576, 'DSC': 6.818181818181819, 'MAT': 44.66019417475729, 'PRO': 3.0927835051546393, 'SMT': 5.555555555555555, 'SPL': 26.923076923076923, 'macro_f1': 0.16309776577788976, 'micro_f1': 0.1959108941104669}
training_time:0.05902838706970215
loss:0.001985985552892089
{'APL': 24.489795918367346, 'CMT': 3.389830508474576, 'DSC': 6.833712984054668, 'MAT': 44.37984496124031, 'PRO': 3.3376123234916566, 'SMT': 5.896805896805897, 'SPL': 26.923076923076923, 'macro_f1': 0.16464382787930198, 'micro_f1': 0.1962929200850805}
training_time:0.07266831398010254
loss:0.001660673413425684
{'APL': 23.776223776223773, 'CMT': 3.3057851239669422, 'DSC': 6.818181818181819, 'MAT': 44.5945945945946, 'PRO': 3.3333333333333335, 'SMT': 5.250596658711217, 'SPL': 28.57142857142857, 'macro_f1': 0.16521449125205753, 'micro_f1': 0.19528415961305925}
training_time:0.06994009017944336
loss:0.0024384057614952326
{'APL': 24.46043165467626, 'CMT': 3.3472803347280333, 'DSC': 6.8493150684931505, 'MAT': 45.825242718446596, 'PRO': 3.324808184143223, 'SMT': 5.326876513317192, 'SPL': 28.57142857142857, 'macro_f1': 0.16815054720747574, 'micro_f1': 0.19969558599695583}
training_time:0.07195711135864258
loss:0.0012752772308886051
training_time:0.06022024154663086
loss:0.000760009279474616
training_time:0.06083846092224121
loss:0.0007280527497641742
training_time:0.06370687484741211
loss:0.0005406013806350529
training_time:0.06920456886291504
loss:0.000586112670134753
training_time:0.060302734375
loss:0.0007039952906779945
training_time:0.05341506004333496
loss:0.0004669753252528608
training_time:0.059740304946899414
loss:0.0005306008970364928
training_time:0.05747270584106445
loss:0.0008820375660434365
training_time:0.060707807540893555
loss:0.00040013238321989775
training_time:0.0641019344329834
loss:0.0003905192425008863
training_time:0.06418228149414062
loss:0.00037150029675103724
training_time:0.05730485916137695
loss:0.0003412598161958158
{'APL': 25.589225589225595, 'CMT': 3.149606299212598, 'DSC': 6.396588486140725, 'MAT': 46.75555555555555, 'PRO': 3.147699757869249, 'SMT': 7.610993657505285, 'SPL': 27.35042735042735, 'macro_f1': 0.17142870956562337, 'micro_f1': 0.2061218758775625}
