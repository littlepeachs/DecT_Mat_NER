Some weights of the model checkpoint at m3rg-iitd/matscibert were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
using device: cuda
72 511 546
['I-APL', 'I-CMT', 'I-DSC', 'I-MAT', 'I-PRO', 'I-SMT', 'I-SPL', 'O']
training_time:0.41849708557128906
loss:0.7201153039932251
training_time:0.21758317947387695
loss:1.1144161224365234
{'APL': 0.0, 'CMT': 20.92050209205021, 'DSC': 0.0, 'MAT': 0.0, 'PRO': 0.0, 'SMT': 0.0, 'SPL': 0.0, 'macro_f1': 0.029886431560071727, 'micro_f1': 0.021052631578947368}
training_time:0.23301243782043457
loss:0.4382839500904083
{'APL': 43.52078239608802, 'CMT': 58.88324873096447, 'DSC': 0.0, 'MAT': 6.402439024390244, 'PRO': 20.21505376344086, 'SMT': 36.94779116465863, 'SPL': 0.0, 'macro_f1': 0.2370990215422032, 'micro_f1': 0.23499197431781704}
training_time:0.23096346855163574
loss:0.17512327432632446
{'APL': 44.930417495029815, 'CMT': 65.22911051212937, 'DSC': 21.83235867446394, 'MAT': 57.24508050089445, 'PRO': 49.41956882255389, 'SMT': 44.39140811455847, 'SPL': 25.0, 'macro_f1': 0.44006849159947137, 'micro_f1': 0.47984826932195357}
training_time:0.258028507232666
loss:0.09904412180185318
{'APL': 51.01214574898785, 'CMT': 65.20547945205479, 'DSC': 17.27941176470588, 'MAT': 51.37254901960784, 'PRO': 33.27102803738318, 'SMT': 41.07142857142857, 'SPL': 56.63716814159292, 'macro_f1': 0.4512131581939444, 'micro_f1': 0.4169690203739883}
training_time:0.24826598167419434
loss:0.1854781061410904
{'APL': 52.41935483870967, 'CMT': 60.792951541850215, 'DSC': 55.392156862745104, 'MAT': 68.28087167070218, 'PRO': 57.939581719597214, 'SMT': 64.46886446886447, 'SPL': 48.68421052631579, 'macro_f1': 0.5828257023268352, 'micro_f1': 0.6040688575899843}
training_time:0.2538135051727295
loss:0.06705240160226822
training_time:0.20937633514404297
loss:0.05616792291402817
{'APL': 57.668711656441715, 'CMT': 68.6046511627907, 'DSC': 52.25885225885225, 'MAT': 65.53191489361701, 'PRO': 57.64119601328903, 'SMT': 60.07067137809188, 'SPL': 54.7008547008547, 'macro_f1': 0.5949669315199104, 'micro_f1': 0.5974695407685099}
training_time:0.2535121440887451
loss:0.005956338718533516
{'APL': 50.0, 'CMT': 69.76744186046511, 'DSC': 53.444676409185796, 'MAT': 70.41800643086818, 'PRO': 61.16731517509728, 'SMT': 58.307210031347964, 'SPL': 55.932203389830505, 'macro_f1': 0.5986240761382783, 'micro_f1': 0.6175950486295314}
training_time:0.2277204990386963
loss:0.04596588388085365
training_time:0.22518134117126465
loss:0.019663525745272636
training_time:0.2185652256011963
loss:0.0075658150017261505
training_time:0.22344732284545898
loss:0.21147467195987701
training_time:0.2198042869567871
loss:0.002541408408433199
training_time:0.21432065963745117
loss:0.0016131872544065118
training_time:0.22009682655334473
loss:0.023882033303380013
training_time:0.22126221656799316
loss:0.04970036447048187
training_time:0.216796875
loss:0.001433981815353036
training_time:0.22501015663146973
loss:0.0015152422711253166
training_time:0.21783041954040527
loss:0.0013472591526806355
training_time:0.21849989891052246
loss:0.003919552080333233
training_time:0.22776389122009277
loss:0.023930544033646584
training_time:0.21715450286865234
loss:0.0018207798711955547
training_time:0.22043108940124512
loss:0.014399370178580284
training_time:0.2238016128540039
loss:0.0006021388689987361
training_time:0.2255573272705078
loss:0.0005514258518815041
training_time:0.23139524459838867
loss:0.015802517533302307
training_time:0.23005890846252441
loss:0.00046472816029563546
training_time:0.22075653076171875
loss:0.0006345973815768957
training_time:0.22839713096618652
loss:0.0014281213516369462
{'APL': 51.26353790613718, 'CMT': 68.66485013623979, 'DSC': 53.92156862745098, 'MAT': 71.69253510716926, 'PRO': 60.588235294117645, 'SMT': 61.170212765957444, 'SPL': 56.00000000000001, 'macro_f1': 0.6047156283386748, 'micro_f1': 0.6227962279622796}
