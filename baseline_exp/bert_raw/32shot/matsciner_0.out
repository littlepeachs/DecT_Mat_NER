Some weights of the model checkpoint at m3rg-iitd/matscibert were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
using device: cuda
77 511 546
['I-APL', 'I-CMT', 'I-DSC', 'I-MAT', 'I-PRO', 'I-SMT', 'I-SPL', 'O']
training_time:0.30790281295776367
loss:1.5288519859313965
training_time:0.23439359664916992
loss:0.535639226436615
{'APL': 8.70712401055409, 'CMT': 43.343653250774, 'DSC': 3.3175355450236967, 'MAT': 36.25730994152047, 'PRO': 24.883068288119738, 'SMT': 19.428571428571427, 'SPL': 5.47945205479452, 'macro_f1': 0.20202387788479703, 'micro_f1': 0.23848643266118993}
training_time:0.2520482540130615
loss:0.2775782346725464
{'APL': 42.23107569721115, 'CMT': 62.82420749279538, 'DSC': 46.48786717752235, 'MAT': 60.848678943154525, 'PRO': 47.664291369754544, 'SMT': 41.68865435356201, 'SPL': 34.69387755102041, 'macro_f1': 0.4806266465500291, 'micro_f1': 0.5130434782608696}
training_time:0.2624857425689697
loss:0.1432129442691803
{'APL': 38.21339950372209, 'CMT': 63.279445727482674, 'DSC': 41.379310344827594, 'MAT': 57.89990186457311, 'PRO': 55.379746835443036, 'SMT': 42.36111111111111, 'SPL': 51.66666666666667, 'macro_f1': 0.5002565457911804, 'micro_f1': 0.5164733178654292}
training_time:0.24593615531921387
loss:0.0457647480070591
{'APL': 53.04659498207885, 'CMT': 68.43501326259947, 'DSC': 55.33498759305212, 'MAT': 67.26998491704374, 'PRO': 59.183673469387756, 'SMT': 53.18352059925093, 'SPL': 48.120300751879704, 'macro_f1': 0.5779629651075608, 'micro_f1': 0.6057017543859649}
training_time:0.244415283203125
loss:0.06957929581403732
training_time:0.23540496826171875
loss:0.02536512166261673
training_time:0.22975754737854004
loss:0.024453014135360718
training_time:0.2312452793121338
loss:0.060364730656147
training_time:0.23035526275634766
loss:0.005815920419991016
training_time:0.22720789909362793
loss:0.005592549219727516
training_time:0.25870275497436523
loss:0.005490090698003769
{'APL': 49.411764705882355, 'CMT': 73.1578947368421, 'DSC': 59.92691839220462, 'MAT': 71.3846153846154, 'PRO': 63.22282189668466, 'SMT': 58.45272206303726, 'SPL': 34.78260869565217, 'macro_f1': 0.586199065535598, 'micro_f1': 0.6381305962000436}
training_time:0.23834538459777832
loss:0.007565652951598167
{'APL': 48.8135593220339, 'CMT': 71.0997442455243, 'DSC': 59.21375921375921, 'MAT': 70.83333333333334, 'PRO': 63.81842456608812, 'SMT': 63.7873754152824, 'SPL': 33.684210526315795, 'macro_f1': 0.5875005808890529, 'micro_f1': 0.6400852878464819}
training_time:0.2444303035736084
loss:0.0031767215114086866
training_time:0.2301177978515625
loss:0.0012028899509459734
training_time:0.23688745498657227
loss:0.00956803746521473
training_time:0.2298908233642578
loss:0.0010696353856474161
{'APL': 48.0565371024735, 'CMT': 64.30260047281324, 'DSC': 62.254901960784316, 'MAT': 70.8841463414634, 'PRO': 64.1860465116279, 'SMT': 60.431654676258994, 'SPL': 49.056603773584904, 'macro_f1': 0.5988178440557232, 'micro_f1': 0.6419698314108252}
training_time:0.24243688583374023
loss:0.0024403610732406378
{'APL': 51.61290322580645, 'CMT': 68.34170854271356, 'DSC': 62.71186440677966, 'MAT': 70.3479576399395, 'PRO': 66.32578524470416, 'SMT': 58.63192182410424, 'SPL': 48.14814814814815, 'macro_f1': 0.6087432700459938, 'micro_f1': 0.6517682794532437}
training_time:0.2337169647216797
loss:0.0008862661197781563
{'APL': 51.28205128205128, 'CMT': 69.58762886597938, 'DSC': 63.32916145181476, 'MAT': 71.87263078089462, 'PRO': 68.18505338078292, 'SMT': 60.256410256410255, 'SPL': 50.0, 'macro_f1': 0.6207327657399047, 'micro_f1': 0.6653645833333334}
training_time:0.23870205879211426
loss:0.0011086721206083894
{'APL': 51.28205128205128, 'CMT': 71.08753315649868, 'DSC': 63.211125158027805, 'MAT': 72.40853658536585, 'PRO': 68.20083682008368, 'SMT': 59.87261146496815, 'SPL': 49.12280701754386, 'macro_f1': 0.6216935735493417, 'micro_f1': 0.66738894907909}
training_time:0.24653124809265137
loss:0.0004393805575091392
training_time:0.23209595680236816
loss:0.0003535084833856672
training_time:0.2326371669769287
loss:0.0007441399502567947
training_time:0.23581886291503906
loss:0.0031889709644019604
training_time:0.22977542877197266
loss:0.0002772861917037517
training_time:0.23282194137573242
loss:0.00026609108317643404
training_time:0.22933006286621094
loss:0.00036126282066106796
training_time:0.22924304008483887
loss:0.00023110091569833457
training_time:0.2258131504058838
loss:0.00024339370429515839
training_time:0.23433375358581543
loss:0.0003330456675030291
{'APL': 53.198653198653204, 'CMT': 70.47146401985111, 'DSC': 63.19526627218936, 'MAT': 72.96918767507002, 'PRO': 68.29268292682926, 'SMT': 64.67391304347827, 'SPL': 49.58677685950412, 'macro_f1': 0.6319827771365362, 'micro_f1': 0.6732275557340831}
