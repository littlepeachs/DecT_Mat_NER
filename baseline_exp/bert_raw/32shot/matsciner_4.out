Some weights of the model checkpoint at m3rg-iitd/matscibert were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
using device: cuda
72 511 546
['I-APL', 'I-CMT', 'I-DSC', 'I-MAT', 'I-PRO', 'I-SMT', 'I-SPL', 'O']
training_time:0.5047018527984619
loss:0.7071223258972168
{'APL': 0.0, 'CMT': 21.259842519685037, 'DSC': 0.0, 'MAT': 0.0, 'PRO': 0.0, 'SMT': 4.790419161676647, 'SPL': 0.0, 'macro_f1': 0.0372146595448024, 'micro_f1': 0.02574750830564784}
training_time:0.4251706600189209
loss:0.5893635153770447
{'APL': 34.92647058823529, 'CMT': 62.96296296296296, 'DSC': 27.3356401384083, 'MAT': 30.338389731621934, 'PRO': 15.94488188976378, 'SMT': 31.818181818181824, 'SPL': 50.847457627118644, 'macro_f1': 0.36310569250898955, 'micro_f1': 0.30665588790083537}
training_time:0.41209983825683594
loss:0.16925087571144104
{'APL': 44.68546637744035, 'CMT': 61.76470588235294, 'DSC': 46.98972099853157, 'MAT': 55.2919708029197, 'PRO': 38.73581847649919, 'SMT': 50.51903114186852, 'SPL': 48.120300751879704, 'macro_f1': 0.4944385920449885, 'micro_f1': 0.48163644816364476}
training_time:0.4225897789001465
loss:0.026658082380890846
training_time:0.41364073753356934
loss:0.04704435542225838
{'APL': 54.71698113207547, 'CMT': 69.35483870967742, 'DSC': 55.4524361948956, 'MAT': 64.29124709527498, 'PRO': 60.237388724035625, 'SMT': 55.59105431309904, 'SPL': 51.2, 'macro_f1': 0.5869199230986545, 'micro_f1': 0.6014783526927139}
training_time:0.4134180545806885
loss:0.02825285866856575
training_time:0.40019702911376953
loss:0.022279128432273865
{'APL': 57.23905723905723, 'CMT': 71.0182767624021, 'DSC': 53.16742081447964, 'MAT': 65.15151515151516, 'PRO': 58.7288817377313, 'SMT': 48.57142857142857, 'SPL': 58.914728682170534, 'macro_f1': 0.5897018699411207, 'micro_f1': 0.5949932945909701}
training_time:0.42594027519226074
loss:0.025396034121513367
{'APL': 57.82312925170069, 'CMT': 71.2707182320442, 'DSC': 59.03890160183066, 'MAT': 70.63429913860611, 'PRO': 60.10928961748634, 'SMT': 56.83453237410071, 'SPL': 57.14285714285714, 'macro_f1': 0.6183624676551798, 'micro_f1': 0.633474105356746}
training_time:0.4021174907684326
loss:0.0010456772288307548
training_time:0.3960433006286621
loss:0.0034440229646861553
training_time:0.40242695808410645
loss:0.0005424627452157438
{'APL': 63.84364820846906, 'CMT': 71.97640117994099, 'DSC': 64.7571606475716, 'MAT': 69.02927580893682, 'PRO': 59.1155934833204, 'SMT': 53.67965367965368, 'SPL': 56.93430656934307, 'macro_f1': 0.6276229136817651, 'micro_f1': 0.6403269754768391}
training_time:0.4015481472015381
loss:0.00043435755651444197
{'APL': 63.63636363636363, 'CMT': 72.99703264094954, 'DSC': 64.66346153846153, 'MAT': 69.12096168294515, 'PRO': 61.52694610778444, 'SMT': 55.000000000000014, 'SPL': 56.93430656934307, 'macro_f1': 0.6341129602512106, 'micro_f1': 0.6485290864852908}
training_time:0.4074821472167969
loss:0.0005614472320303321
{'APL': 65.78073089700996, 'CMT': 75.82089552238807, 'DSC': 64.28571428571429, 'MAT': 68.82043576258454, 'PRO': 62.28782287822878, 'SMT': 55.87044534412956, 'SPL': 55.474452554744516, 'macro_f1': 0.640486424635428, 'micro_f1': 0.6524417069951606}
training_time:0.3910343647003174
loss:0.00042499491246417165
{'APL': 66.21621621621621, 'CMT': 75.14792899408283, 'DSC': 64.81927710843375, 'MAT': 68.28528072837634, 'PRO': 62.08459214501511, 'SMT': 58.4, 'SPL': 55.07246376811593, 'macro_f1': 0.6428939413717717, 'micro_f1': 0.6524254561637739}
training_time:0.37155652046203613
loss:0.0002751007559709251
training_time:0.37076878547668457
loss:0.0007393491105176508
training_time:0.36888813972473145
loss:0.00025035208091139793
training_time:0.3683657646179199
loss:0.00027888876502402127
training_time:0.3680596351623535
loss:0.00017909103189595044
training_time:0.38106489181518555
loss:0.0001881652424344793
training_time:0.38626861572265625
loss:0.0002406542917015031
training_time:0.3816092014312744
loss:0.00021297087369021028
training_time:0.38743162155151367
loss:0.00011874226038344204
training_time:0.3818364143371582
loss:0.00019752394291572273
training_time:0.3901786804199219
loss:0.0001374392450088635
training_time:0.39205408096313477
loss:0.00014823165838606656
training_time:0.4094691276550293
loss:0.0001370265381410718
training_time:0.3810436725616455
loss:0.0001478409394621849
training_time:0.4083216190338135
loss:0.00015716296911705285
training_time:0.38155031204223633
loss:0.00016870276886038482
{'APL': 67.0846394984326, 'CMT': 74.38016528925621, 'DSC': 64.9379932356257, 'MAT': 69.91643454038997, 'PRO': 62.295081967213115, 'SMT': 62.25165562913908, 'SPL': 57.14285714285714, 'macro_f1': 0.6542983247184483, 'micro_f1': 0.6609017912291537}
