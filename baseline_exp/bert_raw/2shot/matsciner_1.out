Some weights of the model checkpoint at m3rg-iitd/matscibert were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
using device: cuda
9 511 546
['I-APL', 'I-CMT', 'I-DSC', 'I-MAT', 'I-PRO', 'I-SMT', 'I-SPL', 'O']
training_time:0.2635834217071533
loss:2.0920631885528564
training_time:0.06496572494506836
loss:0.5573944449424744
training_time:0.06253838539123535
loss:0.41256797313690186
training_time:0.06192636489868164
loss:0.25859686732292175
{'APL': 0.0, 'CMT': 0.0, 'DSC': 0.0, 'MAT': 0.0, 'PRO': 0.0, 'SMT': 0.0, 'SPL': 2.777777777777778, 'macro_f1': 0.003968253968253969, 'micro_f1': 0.0008646779074794639}
training_time:0.07687020301818848
loss:0.1524890810251236
{'APL': 0.0, 'CMT': 0.0, 'DSC': 0.0, 'MAT': 8.433734939759036, 'PRO': 6.666666666666667, 'SMT': 0.0, 'SPL': 25.000000000000007, 'macro_f1': 0.057286288009179585, 'micro_f1': 0.054276315789473686}
training_time:0.07694721221923828
loss:0.09793615341186523
training_time:0.06322693824768066
loss:0.03975379467010498
training_time:0.06610465049743652
loss:0.031408317387104034
training_time:0.06899857521057129
loss:0.013870112597942352
training_time:0.06832289695739746
loss:0.0061701093800365925
{'APL': 1.2422360248447206, 'CMT': 0.0, 'DSC': 1.9184652278177456, 'MAT': 17.90633608815427, 'PRO': 5.852417302798981, 'SMT': 1.3888888888888888, 'SPL': 12.82051282051282, 'macro_f1': 0.058755509075739176, 'micro_f1': 0.07923169267707082}
training_time:0.0800018310546875
loss:0.0041998508386313915
{'APL': 1.234567901234568, 'CMT': 1.0582010582010584, 'DSC': 1.900237529691211, 'MAT': 22.192866578599737, 'PRO': 7.008760951188986, 'SMT': 1.3888888888888888, 'SPL': 17.283950617283953, 'macro_f1': 0.07438210503584058, 'micro_f1': 0.09870740305522914}
training_time:0.07567834854125977
loss:0.0031267874874174595
{'APL': 2.395209580838323, 'CMT': 1.0471204188481675, 'DSC': 3.263403263403264, 'MAT': 26.08695652173913, 'PRO': 9.10209102091021, 'SMT': 2.7397260273972606, 'SPL': 19.047619047619044, 'macro_f1': 0.09097446554393628, 'micro_f1': 0.12174578866768761}
training_time:0.051045894622802734
loss:0.001982229994609952
{'APL': 2.366863905325444, 'CMT': 2.083333333333334, 'DSC': 3.695150115473441, 'MAT': 28.035043804755944, 'PRO': 9.93939393939394, 'SMT': 2.7397260273972606, 'SPL': 19.277108433734938, 'macro_f1': 0.09733802794202044, 'micro_f1': 0.13222516055912356}
training_time:0.06970667839050293
loss:0.0015683270758017898
{'APL': 3.508771929824562, 'CMT': 2.0512820512820515, 'DSC': 4.10958904109589, 'MAT': 29.86536107711138, 'PRO': 10.336538461538462, 'SMT': 2.7397260273972606, 'SPL': 19.277108433734938, 'macro_f1': 0.1026976814599779, 'micro_f1': 0.14093959731543626}
training_time:0.05822420120239258
loss:0.001308705541305244
{'APL': 4.651162790697675, 'CMT': 3.0303030303030307, 'DSC': 4.545454545454546, 'MAT': 30.619684082624538, 'PRO': 10.727056019070321, 'SMT': 2.7397260273972606, 'SPL': 19.277108433734938, 'macro_f1': 0.10798642132754614, 'micro_f1': 0.146612365790448}
training_time:0.059714317321777344
loss:0.0012109380913898349
{'APL': 4.545454545454545, 'CMT': 3.0456852791878175, 'DSC': 4.514672686230249, 'MAT': 31.818181818181824, 'PRO': 11.387900355871885, 'SMT': 2.7397260273972606, 'SPL': 19.277108433734938, 'macro_f1': 0.11046961306579789, 'micro_f1': 0.1527165932452276}
training_time:0.08614468574523926
loss:0.0009942175820469856
{'APL': 4.4692737430167595, 'CMT': 3.0456852791878175, 'DSC': 4.484304932735426, 'MAT': 32.46445497630332, 'PRO': 11.570247933884298, 'SMT': 2.72108843537415, 'SPL': 19.047619047619044, 'macro_f1': 0.11114667764017257, 'micro_f1': 0.15524781341107874}
training_time:0.05476045608520508
loss:0.0008745082886889577
{'APL': 4.4692737430167595, 'CMT': 3.0456852791878175, 'DSC': 4.47427293064877, 'MAT': 32.349468713105075, 'PRO': 11.820330969267138, 'SMT': 2.72108843537415, 'SPL': 19.047619047619044, 'macro_f1': 0.11132534159745536, 'micro_f1': 0.1558063341827448}
training_time:0.057065725326538086
loss:0.0007467034156434238
training_time:0.0667719841003418
loss:0.0006713261245749891
{'APL': 4.444444444444445, 'CMT': 3.061224489795918, 'DSC': 4.464285714285714, 'MAT': 32.470588235294116, 'PRO': 12.042502951593862, 'SMT': 2.72108843537415, 'SPL': 19.047619047619044, 'macro_f1': 0.11178821902629607, 'micro_f1': 0.1569767441860465}
training_time:0.07625722885131836
loss:0.0006239963695406914
training_time:0.0519258975982666
loss:0.010614621452987194
training_time:0.05167031288146973
loss:0.0005251095280982554
training_time:0.06590938568115234
loss:0.0005665845819748938
training_time:0.050176143646240234
loss:0.0005214631091803312
training_time:0.052902936935424805
loss:0.0004564444243442267
training_time:0.05034017562866211
loss:0.0004528438439592719
training_time:0.05607438087463379
loss:0.0004312002856750041
training_time:0.0608518123626709
loss:0.000520126021001488
training_time:0.06522393226623535
loss:0.0004339725710451603
{'APL': 4.166666666666666, 'CMT': 2.843601895734597, 'DSC': 4.184100418410042, 'MAT': 32.10412147505423, 'PRO': 11.659192825112108, 'SMT': 2.298850574712644, 'SPL': 17.97752808988764, 'macro_f1': 0.10747723135082562, 'micro_f1': 0.1534820824881677}
