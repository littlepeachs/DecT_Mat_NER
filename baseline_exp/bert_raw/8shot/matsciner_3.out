Some weights of the model checkpoint at m3rg-iitd/matscibert were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
using device: cuda
23 511 546
['I-APL', 'I-CMT', 'I-DSC', 'I-MAT', 'I-PRO', 'I-SMT', 'I-SPL', 'O']
training_time:0.16645359992980957
loss:2.2124016284942627
training_time:0.07005739212036133
loss:1.0223722457885742
training_time:0.0630502700805664
loss:0.6820303797721863
{'APL': 0.0, 'CMT': 7.9207920792079225, 'DSC': 0.0, 'MAT': 0.0, 'PRO': 0.0, 'SMT': 0.0, 'SPL': 0.0, 'macro_f1': 0.011315417256011318, 'micro_f1': 0.006864006864006864}
training_time:0.07259750366210938
loss:0.4626375138759613
{'APL': 12.549019607843134, 'CMT': 45.29411764705882, 'DSC': 0.4889975550122249, 'MAT': 4.314329738058552, 'PRO': 4.611650485436893, 'SMT': 5.369127516778524, 'SPL': 7.59493670886076, 'macro_f1': 0.11460311322721271, 'micro_f1': 0.09907578558225509}
training_time:0.06212115287780762
loss:0.28334710001945496
training_time:0.05762839317321777
loss:0.27324178814888
{'APL': 31.736526946107784, 'CMT': 50.47923322683706, 'DSC': 0.9685230024213075, 'MAT': 12.429378531073446, 'PRO': 6.9221260815822, 'SMT': 5.298013245033112, 'SPL': 25.26315789473684, 'macro_f1': 0.19013851275398821, 'micro_f1': 0.15727948990435708}
training_time:0.07315397262573242
loss:0.14757829904556274
{'APL': 35.91682419659736, 'CMT': 53.49544072948328, 'DSC': 25.215889464594127, 'MAT': 41.45534729878721, 'PRO': 24.385245901639344, 'SMT': 33.44709897610921, 'SPL': 53.65853658536586, 'macro_f1': 0.3822491187893949, 'micro_f1': 0.34736563410113847}
training_time:0.06263279914855957
loss:0.08475479483604431
training_time:0.0669701099395752
loss:0.05100874602794647
{'APL': 37.49999999999999, 'CMT': 50.43988269794721, 'DSC': 27.019867549668874, 'MAT': 48.32347140039448, 'PRO': 23.25581395348837, 'SMT': 33.44947735191638, 'SPL': 59.54198473282444, 'macro_f1': 0.3993292824089139, 'micro_f1': 0.36231507915909683}
training_time:0.07529282569885254
loss:0.03251169994473457
{'APL': 38.888888888888886, 'CMT': 52.29110512129379, 'DSC': 36.017897091722595, 'MAT': 57.72495755517827, 'PRO': 39.54703832752613, 'SMT': 33.55263157894737, 'SPL': 58.64661654135339, 'macro_f1': 0.4523844787213006, 'micro_f1': 0.4489516864175023}
training_time:0.07030057907104492
loss:0.018553361296653748
{'APL': 43.4065934065934, 'CMT': 51.42857142857142, 'DSC': 37.92325056433409, 'MAT': 61.300813008130085, 'PRO': 46.267432321575065, 'SMT': 36.054421768707485, 'SPL': 62.686567164179095, 'macro_f1': 0.4843823566601295, 'micro_f1': 0.48758865248226957}
training_time:0.07602953910827637
loss:0.012652921490371227
{'APL': 47.59358288770053, 'CMT': 48.607594936708864, 'DSC': 39.671361502347416, 'MAT': 61.2772837510105, 'PRO': 46.24277456647399, 'SMT': 33.94833948339483, 'SPL': 63.565891472868216, 'macro_f1': 0.48700975514357764, 'micro_f1': 0.4922801521593197}
training_time:0.07970237731933594
loss:0.00559191731736064
training_time:0.06600618362426758
loss:0.0242947768419981
{'APL': 49.865951742627345, 'CMT': 46.48910411622276, 'DSC': 38.639125151883356, 'MAT': 61.12903225806452, 'PRO': 44.1251056635672, 'SMT': 34.26294820717131, 'SPL': 67.69230769230768, 'macro_f1': 0.4888622497597773, 'micro_f1': 0.4871969181962384}
training_time:0.08121228218078613
loss:0.0030470741912722588
{'APL': 49.73262032085562, 'CMT': 46.91943127962085, 'DSC': 38.221153846153854, 'MAT': 61.71063149480417, 'PRO': 43.441226575809196, 'SMT': 36.36363636363635, 'SPL': 68.70229007633588, 'macro_f1': 0.4929871285103085, 'micro_f1': 0.48816768086544965}
training_time:0.07766461372375488
loss:0.004265426192432642
{'APL': 50.76923076923077, 'CMT': 47.66355140186916, 'DSC': 40.00000000000001, 'MAT': 62.20472440944881, 'PRO': 42.942686056458506, 'SMT': 37.795275590551185, 'SPL': 67.16417910447761, 'macro_f1': 0.49791378190290864, 'micro_f1': 0.4940914158305463}
training_time:0.0728001594543457
loss:0.002089992631226778
{'APL': 51.83374083129584, 'CMT': 48.73563218390806, 'DSC': 40.476190476190474, 'MAT': 62.87937743190661, 'PRO': 42.27782571182053, 'SMT': 38.13229571984436, 'SPL': 66.17647058823529, 'macro_f1': 0.5007307613474302, 'micro_f1': 0.49767750497677504}
training_time:0.0771481990814209
loss:0.0019392260583117604
training_time:0.06112217903137207
loss:0.0016500113997608423
training_time:0.06190061569213867
loss:0.0012304175179451704
training_time:0.0621190071105957
loss:0.0014144384767860174
training_time:0.06186032295227051
loss:0.0012728453148156404
training_time:0.06428241729736328
loss:0.0010807933285832405
training_time:0.06820821762084961
loss:0.00125856080558151
training_time:0.06235623359680176
loss:0.0009706925484351814
training_time:0.06584548950195312
loss:0.0008813333115540445
training_time:0.06024622917175293
loss:0.0009808678878471255
training_time:0.05731940269470215
loss:0.0009006402688100934
training_time:0.057848215103149414
loss:0.0006965879583731294
training_time:0.07265210151672363
loss:0.0007692218641750515
{'APL': 50.678733031674206, 'CMT': 47.03389830508475, 'DSC': 41.02564102564103, 'MAT': 64.05693950177937, 'PRO': 41.909385113268605, 'SMT': 38.79598662207358, 'SPL': 67.11409395973153, 'macro_f1': 0.500878110798933, 'micro_f1': 0.4995918367346938}
