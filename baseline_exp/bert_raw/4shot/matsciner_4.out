Some weights of the model checkpoint at m3rg-iitd/matscibert were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
using device: cuda
15 511 546
['I-APL', 'I-CMT', 'I-DSC', 'I-MAT', 'I-PRO', 'I-SMT', 'I-SPL', 'O']
training_time:0.11347413063049316
loss:2.1812760829925537
training_time:0.06104016304016113
loss:0.7393991351127625
training_time:0.0564115047454834
loss:0.5655978322029114
training_time:0.05742192268371582
loss:0.3576509356498718
{'APL': 0.0, 'CMT': 0.0, 'DSC': 0.0, 'MAT': 1.2759170653907497, 'PRO': 0.0, 'SMT': 0.0, 'SPL': 2.777777777777778, 'macro_f1': 0.005790992633097897, 'micro_f1': 0.00427715996578272}
training_time:0.0544741153717041
loss:0.1963261216878891
{'APL': 22.641509433962266, 'CMT': 3.703703703703704, 'DSC': 0.4889975550122249, 'MAT': 30.049261083743843, 'PRO': 8.076009501187649, 'SMT': 2.955665024630542, 'SPL': 24.17582417582417, 'macro_f1': 0.13155852925437772, 'micro_f1': 0.1444679351656096}
training_time:0.06015443801879883
loss:0.09613589942455292
{'APL': 25.892857142857146, 'CMT': 8.108108108108107, 'DSC': 2.8846153846153846, 'MAT': 37.47126436781609, 'PRO': 3.5220125786163523, 'SMT': 2.3255813953488373, 'SPL': 33.027522935779814, 'macro_f1': 0.16175994559020246, 'micro_f1': 0.17165242165242164}
training_time:0.06119537353515625
loss:0.06434457749128342
{'APL': 32.857142857142854, 'CMT': 15.972222222222223, 'DSC': 12.107623318385647, 'MAT': 48.67517173699706, 'PRO': 5.762304921968788, 'SMT': 7.8817733990147785, 'SPL': 43.03797468354431, 'macro_f1': 0.23756316162753666, 'micro_f1': 0.2541059807871088}
training_time:0.05256533622741699
loss:0.022706834599375725
{'APL': 34.96143958868895, 'CMT': 29.756097560975608, 'DSC': 29.313543599257883, 'MAT': 50.73086844368012, 'PRO': 19.30745015739769, 'SMT': 13.718411552346568, 'SPL': 43.34975369458128, 'macro_f1': 0.3159108065670401, 'micro_f1': 0.3345195729537367}
training_time:0.06805729866027832
loss:0.015587380155920982
{'APL': 36.18090452261306, 'CMT': 31.11111111111111, 'DSC': 39.876352395672335, 'MAT': 52.24766751484309, 'PRO': 27.647058823529413, 'SMT': 16.5016501650165, 'SPL': 43.0622009569378, 'macro_f1': 0.35232420784246193, 'micro_f1': 0.3756538278649548}
training_time:0.07233905792236328
loss:0.011023139581084251
{'APL': 37.46223564954683, 'CMT': 31.460674157303377, 'DSC': 49.5104895104895, 'MAT': 56.643356643356654, 'PRO': 28.02802802802803, 'SMT': 15.492957746478876, 'SPL': 44.03669724770643, 'macro_f1': 0.37519205568987096, 'micro_f1': 0.4076402321083173}
training_time:0.07974696159362793
loss:0.006066245026886463
{'APL': 36.2369337979094, 'CMT': 31.435079726651484, 'DSC': 50.47489823609226, 'MAT': 57.857142857142854, 'PRO': 27.076923076923077, 'SMT': 16.603773584905664, 'SPL': 46.22641509433962, 'macro_f1': 0.3798730948199491, 'micro_f1': 0.41338289962825275}
training_time:0.07024216651916504
loss:0.003601767122745514
training_time:0.05733990669250488
loss:0.0028648879379034042
training_time:0.0592799186706543
loss:0.0025369287468492985
training_time:0.06283903121948242
loss:0.002155700698494911
training_time:0.05386519432067871
loss:0.001276790862902999
training_time:0.05327200889587402
loss:0.0010049260454252362
training_time:0.05843472480773926
loss:0.000912318064365536
training_time:0.06326103210449219
loss:0.000752057007048279
training_time:0.0621190071105957
loss:0.0008074712823145092
training_time:0.05066633224487305
loss:0.0006312238401733339
training_time:0.05170011520385742
loss:0.0006261534872464836
training_time:0.06014847755432129
loss:0.0007141660316847265
training_time:0.05995655059814453
loss:0.0005017751245759428
training_time:0.058116912841796875
loss:0.0006911300588399172
training_time:0.055811166763305664
loss:0.0005109527846798301
training_time:0.05880141258239746
loss:0.0005142962327226996
training_time:0.05858898162841797
loss:0.0006059211445972323
training_time:0.059688568115234375
loss:0.0005137245170772076
training_time:0.07361102104187012
loss:0.0004625848960131407
{'APL': 35.17915309446254, 'CMT': 30.705394190871367, 'DSC': 49.936628643852984, 'MAT': 58.456486042692944, 'PRO': 26.653696498054476, 'SMT': 14.666666666666666, 'SPL': 45.81497797356829, 'macro_f1': 0.3734471473002418, 'micro_f1': 0.41002068490002297}
