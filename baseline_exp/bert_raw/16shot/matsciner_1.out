Some weights of the model checkpoint at m3rg-iitd/matscibert were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
using device: cuda
41 511 546
['I-APL', 'I-CMT', 'I-DSC', 'I-MAT', 'I-PRO', 'I-SMT', 'I-SPL', 'O']
training_time:0.2082834243774414
loss:0.7196879982948303
{'APL': 0.0, 'CMT': 2.0512820512820515, 'DSC': 0.0, 'MAT': 0.0, 'PRO': 0.0, 'SMT': 0.0, 'SPL': 0.0, 'macro_f1': 0.0029304029304029304, 'micro_f1': 0.0017211703958691911}
training_time:0.18981480598449707
loss:0.8108043074607849
{'APL': 19.631901840490798, 'CMT': 36.8421052631579, 'DSC': 0.0, 'MAT': 15.00682128240109, 'PRO': 17.45762711864407, 'SMT': 21.772151898734176, 'SPL': 0.0, 'macro_f1': 0.15815801057632575, 'micro_f1': 0.17436458048647172}
training_time:0.17392253875732422
loss:0.35543981194496155
training_time:0.14962983131408691
loss:0.1891254335641861
{'APL': 46.15384615384615, 'CMT': 58.22784810126582, 'DSC': 39.50995405819296, 'MAT': 54.991243432574436, 'PRO': 35.16295025728988, 'SMT': 43.67088607594937, 'SPL': 34.18803418803418, 'macro_f1': 0.44557823181021833, 'micro_f1': 0.448376151236064}
training_time:0.1970231533050537
loss:0.04178408160805702
training_time:0.14942383766174316
loss:0.08124945312738419
{'APL': 41.7910447761194, 'CMT': 66.08695652173913, 'DSC': 36.23693379790941, 'MAT': 63.627906976744185, 'PRO': 9.79689366786141, 'SMT': 45.643153526970956, 'SPL': 59.50413223140495, 'macro_f1': 0.4609814592839278, 'micro_f1': 0.43224501589136094}
training_time:0.16575884819030762
loss:0.020169531926512718
{'APL': 51.94029850746269, 'CMT': 67.1957671957672, 'DSC': 48.44384303112314, 'MAT': 61.04553119730185, 'PRO': 42.0, 'SMT': 50.49833887043188, 'SPL': 51.89873417721519, 'macro_f1': 0.5328893042561457, 'micro_f1': 0.5256135334762927}
training_time:0.15709352493286133
loss:0.026713019236922264
{'APL': 52.1505376344086, 'CMT': 68.44919786096256, 'DSC': 52.24489795918367, 'MAT': 64.7766323024055, 'PRO': 54.48818897637795, 'SMT': 52.117263843648196, 'SPL': 49.729729729729726, 'macro_f1': 0.5627949261524516, 'micro_f1': 0.5745405037440436}
training_time:0.16460466384887695
loss:0.036959584802389145
training_time:0.14908599853515625
loss:0.053610093891620636
training_time:0.1484689712524414
loss:0.0014611134538426995
training_time:0.15512728691101074
loss:0.0007654749788343906
training_time:0.16841411590576172
loss:0.0007114121690392494
training_time:0.14780211448669434
loss:0.0012868671910837293
training_time:0.1478724479675293
loss:0.00041750489617697895
training_time:0.1500244140625
loss:0.046688780188560486
{'APL': 55.487804878048784, 'CMT': 69.44444444444446, 'DSC': 56.25, 'MAT': 64.27915518824611, 'PRO': 39.298892988929886, 'SMT': 57.05128205128206, 'SPL': 58.26771653543307, 'macro_f1': 0.5715418515519777, 'micro_f1': 0.550949050949051}
training_time:0.14661931991577148
loss:0.0009936656570062041
{'APL': 54.86725663716815, 'CMT': 70.52341597796143, 'DSC': 57.61772853185595, 'MAT': 64.71631205673759, 'PRO': 41.77777777777777, 'SMT': 57.7639751552795, 'SPL': 56.923076923076934, 'macro_f1': 0.5774136329426534, 'micro_f1': 0.5613950108985227}
training_time:0.1679401397705078
loss:0.03953645005822182
{'APL': 55.62130177514793, 'CMT': 70.84468664850135, 'DSC': 58.96739130434783, 'MAT': 64.7419072615923, 'PRO': 45.95300261096605, 'SMT': 59.07692307692307, 'SPL': 56.923076923076934, 'macro_f1': 0.588754699429365, 'micro_f1': 0.5768863419293219}
training_time:0.1611309051513672
loss:0.0003973678103648126
training_time:0.1647171974182129
loss:0.0005440680542960763
training_time:0.15014958381652832
loss:0.0005533939693123102
training_time:0.14919376373291016
loss:0.000525006849784404
training_time:0.14573240280151367
loss:0.0005047519807703793
training_time:0.14750003814697266
loss:0.00039634446147829294
training_time:0.14155268669128418
loss:0.000427818187745288
training_time:0.1499786376953125
loss:0.0005723426584154367
training_time:0.14825034141540527
loss:0.00031854325789026916
training_time:0.14644622802734375
loss:0.00018447866023052484
training_time:0.14458847045898438
loss:0.0003460085135884583
training_time:0.14208197593688965
loss:0.0003222337400075048
{'APL': 56.666666666666664, 'CMT': 70.52896725440806, 'DSC': 58.0891719745223, 'MAT': 65.91999999999999, 'PRO': 46.24183006535947, 'SMT': 61.37566137566138, 'SPL': 56.52173913043478, 'macro_f1': 0.593348623524361, 'micro_f1': 0.5825242718446602}
