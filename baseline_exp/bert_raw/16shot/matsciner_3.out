Some weights of the model checkpoint at m3rg-iitd/matscibert were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
using device: cuda
36 511 546
['I-APL', 'I-CMT', 'I-DSC', 'I-MAT', 'I-PRO', 'I-SMT', 'I-SPL', 'O']
training_time:0.21877479553222656
loss:1.5795953273773193
training_time:0.1890394687652588
loss:1.1155636310577393
{'APL': 0.0, 'CMT': 1.0752688172043012, 'DSC': 0.0, 'MAT': 0.0, 'PRO': 0.0, 'SMT': 0.0, 'SPL': 0.0, 'macro_f1': 0.0015360983102918587, 'micro_f1': 0.0008598452278589854}
training_time:0.1603071689605713
loss:0.49856245517730713
{'APL': 0.0, 'CMT': 24.47257383966245, 'DSC': 1.9417475728155338, 'MAT': 0.9600000000000001, 'PRO': 0.0, 'SMT': 6.024096385542169, 'SPL': 0.0, 'macro_f1': 0.04771202542574307, 'micro_f1': 0.03418090871196332}
training_time:0.15324711799621582
loss:0.45446866750717163
{'APL': 9.95475113122172, 'CMT': 47.109207708779444, 'DSC': 24.208566108007446, 'MAT': 60.87689713322092, 'PRO': 35.59822747415066, 'SMT': 28.215767634854767, 'SPL': 44.57142857142857, 'macro_f1': 0.3579069225166622, 'micro_f1': 0.40479421076436}
training_time:0.14731287956237793
loss:0.11625871062278748
training_time:0.1527097225189209
loss:0.1337241381406784
{'APL': 38.57142857142858, 'CMT': 56.61538461538461, 'DSC': 30.956521739130437, 'MAT': 57.83582089552238, 'PRO': 42.70905321354526, 'SMT': 41.17647058823529, 'SPL': 58.88888888888888, 'macro_f1': 0.46679081216019347, 'micro_f1': 0.4631429248637118}
training_time:0.15866637229919434
loss:0.03280346095561981
{'APL': 46.76923076923077, 'CMT': 59.78260869565217, 'DSC': 37.425149700598794, 'MAT': 56.32730732635585, 'PRO': 38.15789473684211, 'SMT': 40.93567251461989, 'SPL': 62.96296296296296, 'macro_f1': 0.48908689529466076, 'micro_f1': 0.46466602129719264}
training_time:0.1585984230041504
loss:0.004787002224475145
training_time:0.1490938663482666
loss:0.005245919805020094
{'APL': 46.470588235294116, 'CMT': 62.03208556149733, 'DSC': 55.035128805620616, 'MAT': 67.26973684210526, 'PRO': 33.883579496090356, 'SMT': 41.359773371104815, 'SPL': 48.68421052631579, 'macro_f1': 0.5067644326257547, 'micro_f1': 0.5153153153153154}
training_time:0.15717720985412598
loss:0.013105388730764389
{'APL': 48.29931972789115, 'CMT': 62.809917355371894, 'DSC': 52.19512195121951, 'MAT': 64.16382252559727, 'PRO': 36.11349957007739, 'SMT': 38.70967741935484, 'SPL': 62.893081761006286, 'macro_f1': 0.5216920575864548, 'micro_f1': 0.51156271899089}
training_time:0.14510822296142578
loss:0.004953084513545036
{'APL': 51.298701298701296, 'CMT': 65.0137741046832, 'DSC': 55.893074119076545, 'MAT': 65.9303313508921, 'PRO': 47.85658612626656, 'SMT': 50.12787723785167, 'SPL': 60.97560975609756, 'macro_f1': 0.5672799342765271, 'micro_f1': 0.5633178088267908}
training_time:0.17340564727783203
loss:0.0026792995631694794
training_time:0.1564922332763672
loss:0.00035110654425807297
training_time:0.14403843879699707
loss:0.005408966448158026
training_time:0.14725518226623535
loss:0.0006126103107817471
{'APL': 53.75000000000001, 'CMT': 65.70605187319885, 'DSC': 56.249999999999986, 'MAT': 69.85413290113452, 'PRO': 45.034116755117516, 'SMT': 51.26582278481012, 'SPL': 59.57446808510638, 'macro_f1': 0.5734779891419532, 'micro_f1': 0.5702917771883289}
training_time:0.15807342529296875
loss:0.006396568845957518
training_time:0.14467644691467285
loss:0.0004085941764060408
training_time:0.1421222686767578
loss:0.00030516303377225995
training_time:0.14043259620666504
loss:0.0005194605910219252
training_time:0.14743804931640625
loss:0.00021252785518299788
training_time:0.14484596252441406
loss:0.0006697484641335905
training_time:0.14290118217468262
loss:0.0005758117185905576
training_time:0.15477418899536133
loss:0.0006764066056348383
training_time:0.14251136779785156
loss:0.0007078233757056296
training_time:0.14356279373168945
loss:0.0003259857767261565
training_time:0.14932918548583984
loss:0.0006536386208608747
training_time:0.15506958961486816
loss:0.0004856720333918929
training_time:0.1586589813232422
loss:0.00042494546505622566
training_time:0.14587926864624023
loss:0.001091910875402391
training_time:0.16292881965637207
loss:0.00044286245247349143
{'APL': 54.970760233918135, 'CMT': 65.4054054054054, 'DSC': 56.10328638497653, 'MAT': 70.54436987322892, 'PRO': 44.603288062902074, 'SMT': 55.82655826558265, 'SPL': 61.0, 'macro_f1': 0.5835052403228768, 'micro_f1': 0.5758259798891853}
