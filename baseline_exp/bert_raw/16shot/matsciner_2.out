Some weights of the model checkpoint at m3rg-iitd/matscibert were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
using device: cuda
46 511 546
['I-APL', 'I-CMT', 'I-DSC', 'I-MAT', 'I-PRO', 'I-SMT', 'I-SPL', 'O']
training_time:0.18926596641540527
loss:1.038133978843689
training_time:0.15308189392089844
loss:0.7911598682403564
{'APL': 0.0, 'CMT': 0.9302325581395351, 'DSC': 0.0, 'MAT': 0.0, 'PRO': 0.0, 'SMT': 0.0, 'SPL': 0.0, 'macro_f1': 0.0013289036544850501, 'micro_f1': 0.0008525149190110826}
training_time:0.15768885612487793
loss:0.5041776895523071
{'APL': 11.607142857142856, 'CMT': 4.3887147335423204, 'DSC': 9.842519685039369, 'MAT': 11.386861313868613, 'PRO': 16.427889207258836, 'SMT': 7.547169811320755, 'SPL': 29.7029702970297, 'macro_f1': 0.12986181129314636, 'micro_f1': 0.12467700258397932}
training_time:0.1603691577911377
loss:0.2987177073955536
{'APL': 33.497536945812804, 'CMT': 36.73469387755102, 'DSC': 22.99270072992701, 'MAT': 52.92368681863231, 'PRO': 24.798387096774192, 'SMT': 25.581395348837212, 'SPL': 54.54545454545454, 'macro_f1': 0.3586769362328415, 'micro_f1': 0.35562233909341345}
training_time:0.165313720703125
loss:0.36861452460289
{'APL': 44.866920152091254, 'CMT': 45.14563106796117, 'DSC': 32.22591362126246, 'MAT': 65.13911620294598, 'PRO': 37.54578754578754, 'SMT': 31.41993957703928, 'SPL': 54.19354838709677, 'macro_f1': 0.4436240807916921, 'micro_f1': 0.4640667157223448}
training_time:0.14513683319091797
loss:0.09971778839826584
{'APL': 46.808510638297875, 'CMT': 54.627539503386004, 'DSC': 45.97156398104266, 'MAT': 67.6783004552352, 'PRO': 57.29166666666667, 'SMT': 45.631067961165044, 'SPL': 51.11111111111111, 'macro_f1': 0.5273139433098636, 'micro_f1': 0.5606469002695418}
training_time:0.14083504676818848
loss:0.08024641871452332
training_time:0.1392810344696045
loss:0.026560472324490547
training_time:0.13344717025756836
loss:0.008992476388812065
{'APL': 57.333333333333336, 'CMT': 62.47086247086248, 'DSC': 40.80996884735203, 'MAT': 67.58064516129032, 'PRO': 50.76660988074958, 'SMT': 40.69264069264069, 'SPL': 59.13043478260869, 'macro_f1': 0.541120707384053, 'micro_f1': 0.5562817719680465}
training_time:0.1534891128540039
loss:0.008932952769100666
{'APL': 55.62130177514793, 'CMT': 60.810810810810814, 'DSC': 45.73082489146165, 'MAT': 69.48356807511738, 'PRO': 52.55230125523013, 'SMT': 43.983402489626556, 'SPL': 57.85123966942148, 'macro_f1': 0.5514763556668799, 'micro_f1': 0.5724233983286907}
training_time:0.1561450958251953
loss:0.028139833360910416
training_time:0.13331365585327148
loss:0.0030311571899801493
training_time:0.13784050941467285
loss:0.06997435539960861
training_time:0.14034080505371094
loss:0.007193581201136112
training_time:0.14119458198547363
loss:0.07957728952169418
training_time:0.13538122177124023
loss:0.004227480851113796
training_time:0.13691449165344238
loss:0.03356385976076126
training_time:0.13629865646362305
loss:0.0041651478968560696
training_time:0.13999009132385254
loss:0.05725342035293579
{'APL': 51.412429378531066, 'CMT': 60.273972602739725, 'DSC': 52.61984392419174, 'MAT': 66.05351170568561, 'PRO': 54.60472697636513, 'SMT': 50.75757575757576, 'SPL': 56.250000000000014, 'macro_f1': 0.5599600862072701, 'micro_f1': 0.5736331569664903}
training_time:0.1499948501586914
loss:0.01938856765627861
training_time:0.12511849403381348
loss:0.006119787693023682
{'APL': 51.81058495821728, 'CMT': 59.1743119266055, 'DSC': 52.74725274725275, 'MAT': 68.19296811120196, 'PRO': 56.71167593328038, 'SMT': 50.74626865671642, 'SPL': 59.354838709677416, 'macro_f1': 0.5696255729185026, 'micro_f1': 0.5856832971800434}
training_time:0.1550600528717041
loss:0.006552098784595728
{'APL': 56.32183908045977, 'CMT': 60.41189931350114, 'DSC': 54.347826086956516, 'MAT': 68.37469975980784, 'PRO': 57.120253164556964, 'SMT': 51.09489051094891, 'SPL': 58.44155844155844, 'macro_f1': 0.580161380511128, 'micro_f1': 0.5953508394317694}
training_time:0.14740800857543945
loss:0.029543999582529068
{'APL': 56.547619047619044, 'CMT': 61.82669789227167, 'DSC': 55.119825708060986, 'MAT': 69.15739268680447, 'PRO': 56.89381933438985, 'SMT': 51.98555956678701, 'SPL': 57.516339869281055, 'macro_f1': 0.5843532201503059, 'micro_f1': 0.6003023105160873}
training_time:0.14467287063598633
loss:0.007549008820205927
training_time:0.1300351619720459
loss:0.013005178421735764
training_time:0.12978577613830566
loss:0.013488209806382656
training_time:0.13642406463623047
loss:0.001629791222512722
training_time:0.13094711303710938
loss:0.0021612036507576704
training_time:0.12871003150939941
loss:0.002543200273066759
training_time:0.13031840324401855
loss:0.0013506865361705422
{'APL': 56.98324022346368, 'CMT': 60.698689956331876, 'DSC': 54.26515930113052, 'MAT': 70.02923976608187, 'PRO': 57.27069351230426, 'SMT': 53.53846153846153, 'SPL': 58.536585365853654, 'macro_f1': 0.5876029566623249, 'micro_f1': 0.6027671947062363}
