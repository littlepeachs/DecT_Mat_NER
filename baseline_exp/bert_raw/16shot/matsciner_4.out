Some weights of the model checkpoint at m3rg-iitd/matscibert were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
using device: cuda
45 511 546
['I-APL', 'I-CMT', 'I-DSC', 'I-MAT', 'I-PRO', 'I-SMT', 'I-SPL', 'O']
training_time:0.2114543914794922
loss:1.4090675115585327
training_time:0.21844768524169922
loss:0.5208807587623596
training_time:0.1485133171081543
loss:0.4191340506076813
{'APL': 30.466830466830462, 'CMT': 54.623655913978496, 'DSC': 2.4271844660194173, 'MAT': 45.007451564828614, 'PRO': 15.931108719052745, 'SMT': 22.50639386189258, 'SPL': 27.27272727272727, 'macro_f1': 0.2831933603790423, 'micro_f1': 0.30267596132223973}
training_time:0.17860174179077148
loss:0.3527924418449402
{'APL': 38.58520900321544, 'CMT': 59.89847715736041, 'DSC': 10.454545454545457, 'MAT': 55.01858736059481, 'PRO': 10.955710955710956, 'SMT': 38.775510204081634, 'SPL': 54.166666666666664, 'macro_f1': 0.3826495811459648, 'micro_f1': 0.3639465453511515}
training_time:0.16692638397216797
loss:0.10138905793428421
{'APL': 53.7142857142857, 'CMT': 66.4804469273743, 'DSC': 45.81196581196581, 'MAT': 57.416267942583744, 'PRO': 43.05084745762712, 'SMT': 43.50877192982456, 'SPL': 53.89221556886228, 'macro_f1': 0.5198211447893193, 'micro_f1': 0.511127063890883}
training_time:0.18384313583374023
loss:0.04508967325091362
{'APL': 53.07443365695793, 'CMT': 64.92753623188406, 'DSC': 45.310245310245314, 'MAT': 58.06451612903225, 'PRO': 43.77162629757785, 'SMT': 44.44444444444444, 'SPL': 68.08510638297872, 'macro_f1': 0.5395398692187436, 'micro_f1': 0.5136284071017755}
training_time:0.18061542510986328
loss:0.013929479755461216
{'APL': 45.28301886792453, 'CMT': 69.94535519125684, 'DSC': 48.941798941798936, 'MAT': 60.314523589269186, 'PRO': 50.380388841927314, 'SMT': 52.56410256410257, 'SPL': 67.71653543307086, 'macro_f1': 0.5644938906133574, 'micro_f1': 0.5486552567237164}
training_time:0.14952945709228516
loss:0.005440796259790659
{'APL': 48.461538461538474, 'CMT': 72.29551451187334, 'DSC': 51.68236877523553, 'MAT': 64.13793103448276, 'PRO': 51.174496644295296, 'SMT': 53.776435045317214, 'SPL': 65.07936507936508, 'macro_f1': 0.5808680707887253, 'micro_f1': 0.5721784776902887}
training_time:0.16653704643249512
loss:0.0016403638292104006
training_time:0.1609961986541748
loss:0.003497195662930608
training_time:0.14438509941101074
loss:0.0010694684460759163
training_time:0.14619159698486328
loss:0.02401864156126976
training_time:0.14800047874450684
loss:0.0006808672333136201
training_time:0.14657092094421387
loss:0.00043688720325008035
training_time:0.1460552215576172
loss:0.0005493073840625584
training_time:0.14915752410888672
loss:0.00041429486009292305
training_time:0.14305925369262695
loss:0.00043147648102603853
training_time:0.14588356018066406
loss:0.0024031184148043394
training_time:0.1473085880279541
loss:0.003751590847969055
{'APL': 51.49700598802396, 'CMT': 71.93460490463217, 'DSC': 61.98243412797992, 'MAT': 66.50326797385621, 'PRO': 48.09027777777778, 'SMT': 55.072463768115945, 'SPL': 55.42168674698795, 'macro_f1': 0.5864310589819628, 'micro_f1': 0.588369441277081}
training_time:0.1565992832183838
loss:0.0007162591791711748
{'APL': 53.6144578313253, 'CMT': 72.6775956284153, 'DSC': 60.94986807387863, 'MAT': 65.57645134914145, 'PRO': 47.79541446208113, 'SMT': 54.33526011560694, 'SPL': 56.09756097560975, 'macro_f1': 0.5872094406229407, 'micro_f1': 0.5852417302798982}
training_time:0.1708354949951172
loss:0.0004613030469045043
training_time:0.15064072608947754
loss:0.000608020753134042
{'APL': 55.948553054662376, 'CMT': 72.13114754098359, 'DSC': 60.22408963585434, 'MAT': 65.83953680727875, 'PRO': 44.0771349862259, 'SMT': 55.15151515151514, 'SPL': 60.8695652173913, 'macro_f1': 0.591773631991302, 'micro_f1': 0.5799043062200957}
training_time:0.17026042938232422
loss:0.0001873952423920855
training_time:0.140852689743042
loss:0.00031946031958796084
training_time:0.14580845832824707
loss:0.00046754945651628077
training_time:0.14388513565063477
loss:0.0004019478219561279
training_time:0.15538501739501953
loss:0.0004166802391409874
training_time:0.16174936294555664
loss:0.0003113407292403281
training_time:0.14612126350402832
loss:0.000281971791991964
training_time:0.14814186096191406
loss:0.0002476371009834111
{'APL': 57.3134328358209, 'CMT': 70.05076142131979, 'DSC': 60.550458715596335, 'MAT': 66.51515151515152, 'PRO': 44.058976582827405, 'SMT': 57.21784776902887, 'SPL': 62.7906976744186, 'macro_f1': 0.5978533235916621, 'micro_f1': 0.5847720230190349}
