Some weights of the model checkpoint at m3rg-iitd/matscibert were not used when initializing BertForTokenClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForTokenClassification were not initialized from the model checkpoint at m3rg-iitd/matscibert and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
using device: cuda
45 511 546
['I-APL', 'I-CMT', 'I-DSC', 'I-MAT', 'I-PRO', 'I-SMT', 'I-SPL', 'O']
BertForTokenClassification(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31090, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=8, bias=True)
)
training_time:0.12833523750305176
loss:1.7627729177474976
{'APL': 0.6896551724137931, 'CMT': 0.0, 'DSC': 0.0, 'MAT': 1.1778563015312131, 'PRO': 7.201309328968904, 'SMT': 0.42105263157894746, 'SPL': 0.0, 'macro_f1': 0.01355696204927551, 'micro_f1': 0.034482758620689655}
training_time:0.09224200248718262
loss:1.2889519929885864
training_time:0.08361983299255371
loss:1.0748581886291504
training_time:0.08240246772766113
loss:0.7470396161079407
training_time:0.08679938316345215
loss:1.1054725646972656
training_time:0.08851957321166992
loss:1.0712285041809082
training_time:0.09231686592102051
loss:1.0583887100219727
training_time:0.08519148826599121
loss:0.7162795662879944
training_time:0.08255505561828613
loss:0.5828943252563477
training_time:0.08251833915710449
loss:0.6177978515625
training_time:0.08315014839172363
loss:0.871638834476471
training_time:0.08415389060974121
loss:0.6441827416419983
training_time:0.08294320106506348
loss:0.5915561318397522
training_time:0.08396506309509277
loss:0.7260592579841614
training_time:0.08240032196044922
loss:0.5017151236534119
training_time:0.08283567428588867
loss:0.6120325922966003
{'APL': 0.0, 'CMT': 3.8277511961722492, 'DSC': 0.4878048780487805, 'MAT': 0.6430868167202572, 'PRO': 0.5412719891745602, 'SMT': 3.9473684210526314, 'SPL': 2.8169014084507045, 'macro_f1': 0.017520263870884546, 'micro_f1': 0.010975094976783454}
training_time:0.08805370330810547
loss:0.5827601552009583
{'APL': 1.176470588235294, 'CMT': 7.964601769911504, 'DSC': 1.4527845036319613, 'MAT': 0.9615384615384616, 'PRO': 0.5383580080753702, 'SMT': 5.161290322580645, 'SPL': 2.8169014084507045, 'macro_f1': 0.028674207232034205, 'micro_f1': 0.019150707743547043}
training_time:0.08645415306091309
loss:0.5183073282241821
{'APL': 1.1560693641618496, 'CMT': 11.76470588235294, 'DSC': 3.3333333333333335, 'MAT': 1.5974440894568689, 'PRO': 0.7989347536617843, 'SMT': 6.134969325153375, 'SPL': 2.777777777777778, 'macro_f1': 0.03937604932271132, 'micro_f1': 0.02947196070405239}
training_time:0.08773231506347656
loss:0.5314761996269226
{'APL': 3.4090909090909096, 'CMT': 12.749003984063744, 'DSC': 3.286384976525822, 'MAT': 2.535657686212361, 'PRO': 0.7926023778071334, 'SMT': 6.134969325153375, 'SPL': 2.777777777777778, 'macro_f1': 0.045264981480901606, 'micro_f1': 0.034733441033925685}
training_time:0.0854196548461914
loss:0.670390784740448
{'APL': 3.3333333333333335, 'CMT': 13.95348837209302, 'DSC': 3.286384976525822, 'MAT': 4.075235109717868, 'PRO': 1.0430247718383312, 'SMT': 5.9880239520958085, 'SPL': 2.73972602739726, 'macro_f1': 0.04917030934714491, 'micro_f1': 0.04065364687126345}
training_time:0.09092235565185547
loss:0.6081438064575195
{'APL': 3.278688524590164, 'CMT': 13.95348837209302, 'DSC': 3.7383177570093453, 'MAT': 4.375, 'PRO': 1.0362694300518136, 'SMT': 5.9880239520958085, 'SPL': 10.526315789473683, 'macro_f1': 0.06128014832187691, 'micro_f1': 0.044374009508716325}
training_time:0.08506631851196289
loss:0.36750566959381104
{'APL': 4.3478260869565215, 'CMT': 13.95348837209302, 'DSC': 5.092592592592593, 'MAT': 6.17283950617284, 'PRO': 1.0309278350515463, 'SMT': 7.18562874251497, 'SPL': 10.526315789473683, 'macro_f1': 0.06901374132122168, 'micro_f1': 0.05273514364423456}
training_time:0.0866241455078125
loss:0.5454909801483154
{'APL': 4.324324324324325, 'CMT': 14.84375, 'DSC': 6.436781609195402, 'MAT': 6.461538461538462, 'PRO': 1.7948717948717947, 'SMT': 7.100591715976331, 'SPL': 15.384615384615383, 'macro_f1': 0.08049496184360243, 'micro_f1': 0.060321190755973364}
training_time:0.08339715003967285
loss:0.4679282009601593
{'APL': 5.347593582887701, 'CMT': 14.785992217898833, 'DSC': 6.422018348623852, 'MAT': 6.727828746177369, 'PRO': 1.7902813299232732, 'SMT': 7.0588235294117645, 'SPL': 15.384615384615383, 'macro_f1': 0.08216736162791168, 'micro_f1': 0.06162246489859595}
training_time:0.08387517929077148
loss:0.4527755081653595
{'APL': 5.291005291005291, 'CMT': 14.728682170542637, 'DSC': 7.289293849658314, 'MAT': 7.305936073059362, 'PRO': 2.038216560509554, 'SMT': 5.9171597633136095, 'SPL': 17.72151898734177, 'macro_f1': 0.0861311609934722, 'micro_f1': 0.06521739130434782}
training_time:0.09835219383239746
loss:0.593072772026062
{'APL': 4.2105263157894735, 'CMT': 14.84375, 'DSC': 7.727272727272727, 'MAT': 7.598784194528875, 'PRO': 2.2929936305732483, 'SMT': 5.9171597633136095, 'SPL': 17.72151898734177, 'macro_f1': 0.08616000802688528, 'micro_f1': 0.06674427629026}
training_time:0.08621382713317871
loss:0.46141842007637024
{'APL': 4.18848167539267, 'CMT': 14.84375, 'DSC': 8.16326530612245, 'MAT': 7.890743550834597, 'PRO': 2.2900763358778624, 'SMT': 5.9171597633136095, 'SPL': 17.72151898734177, 'macro_f1': 0.0871642794555471, 'micro_f1': 0.068190623789229}
training_time:0.08658218383789062
loss:0.4728497266769409
{'APL': 4.18848167539267, 'CMT': 14.84375, 'DSC': 8.16326530612245, 'MAT': 7.890743550834597, 'PRO': 2.2871664548919948, 'SMT': 5.9523809523809526, 'SPL': 17.72151898734177, 'macro_f1': 0.08721043846709206, 'micro_f1': 0.068190623789229}
training_time:0.08379030227661133
loss:0.4464469254016876
training_time:0.08228397369384766
loss:0.4436594247817993
Traceback (most recent call last):
  File "/home/liwentao/Dec-Tuning-in-Mat/baseline1/bert_ner_raw.py", line 354, in <module>
    model = torch.load("/home/liwentao/Dec-Tuning-in-Mat/model/matscibert_raw.pt")
  File "/home/liwentao/miniconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py", line 705, in load
    with _open_zipfile_reader(opened_file) as opened_zipfile:
  File "/home/liwentao/miniconda3/envs/py38/lib/python3.8/site-packages/torch/serialization.py", line 243, in __init__
    super(_open_zipfile_reader, self).__init__(torch._C.PyTorchFileReader(name_or_buffer))
RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory
