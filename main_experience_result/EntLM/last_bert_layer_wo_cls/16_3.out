09/14/2023 09:08:04 - INFO - __main__ - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

loading configuration file /home/liwentao/learn/DecT_Mat_NER/model/config.json
Model config BertConfig {
  "_name_or_path": "/home/liwentao/learn/DecT_Mat_NER/model",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.27.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

loading configuration file /home/liwentao/learn/DecT_Mat_NER/model/config.json
Model config BertConfig {
  "_name_or_path": "/home/liwentao/learn/DecT_Mat_NER/model",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.27.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

loading file vocab.txt
loading file tokenizer.json
loading file added_tokens.json
loading file special_tokens_map.json
loading file tokenizer_config.json
loading configuration file /home/liwentao/learn/DecT_Mat_NER/model/config.json
Model config BertConfig {
  "_name_or_path": "/home/liwentao/learn/DecT_Mat_NER/model",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.27.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

loading weights file /home/liwentao/learn/DecT_Mat_NER/model/pytorch_model.bin
Generate config GenerationConfig {
  "_from_model_config": true,
  "pad_token_id": 0,
  "transformers_version": "4.27.1"
}

All model checkpoint weights were used when initializing BertForMaskedLM.

All the weights of BertForMaskedLM were initialized from the model checkpoint at /home/liwentao/learn/DecT_Mat_NER/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.
Generation config file not found, using a generation config created from the model config.
/home/liwentao/learn/DecT_Mat_NER/baseline2_EntLM/train_transformer.py:561: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric("./seqeval_metric.py")
09/14/2023 09:08:15 - INFO - __main__ - ***** Running training *****
09/14/2023 09:08:15 - INFO - __main__ -   Num examples = 36
09/14/2023 09:08:15 - INFO - __main__ -   Num Epochs = 60
09/14/2023 09:08:15 - INFO - __main__ -   Instantaneous batch size per device = 4
09/14/2023 09:08:15 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4
09/14/2023 09:08:15 - INFO - __main__ -   Gradient Accumulation steps = 1
09/14/2023 09:08:15 - INFO - __main__ -   Total optimization steps = 540
Loading label map from scripts/matsciner/final_verbalizer.json...
{'I-CMT': ['electron', 'diffraction', 'microscopy', 'spectroscopy', 'transmission', 'test'], 'I-MAT': ['oxide', 'silicon', 'carbon', 'graphene', 'aluminum', 'oxides'], 'I-DSC': ['films', 'doped', 'thin', 'film', 'alloy'], 'I-PRO': ['properties', 'structure', 'magnetic', 'band', 'conductivity', 'electrical'], 'I-SMT': ['annealing', 'gel', 'plasma', 'hydrothermal', 'annealed', 'vapor'], 'I-APL': ['coatings', 'coating', 'solar', 'cells', 'electrode', 'applications', 'electrodes', 'catalysts', 'cathode'], 'I-SPL': ['cubic', 'hexagonal', 'rock', 'ch']}
{'O': 0, 'I-CMT': 1, 'I-MAT': 2, 'I-DSC': 3, 'I-PRO': 4, 'I-SMT': 5, 'I-APL': 6, 'I-SPL': 7, 'B-CMT': 8, 'B-MAT': 9, 'B-DSC': 10, 'B-PRO': 11, 'B-SMT': 12, 'B-APL': 13, 'B-SPL': 14}
I-CMT
[3081, 10314, 5820, 7779, 2856, 856]
I-MAT
[6678, 8605, 3473, 11106, 15028, 20464]
I-DSC
[7423, 21155, 5197, 5796, 15937]
I-PRO
[1784, 1187, 3510, 2102, 9370, 4874]
I-SMT
[12040, 4051, 2780, 29973, 27202, 12766]
I-APL
[20189, 9754, 6911, 576, 6665, 2040, 8438, 15834, 19112]
I-SPL
[13879, 22235, 8863, 249]
{'I-CMT': ['electron', 'diffraction', 'microscopy', 'spectroscopy', 'transmission', 'test'], 'I-MAT': ['oxide', 'silicon', 'carbon', 'graphene', 'aluminum', 'oxides'], 'I-DSC': ['films', 'doped', 'thin', 'film', 'alloy'], 'I-PRO': ['properties', 'structure', 'magnetic', 'band', 'conductivity', 'electrical'], 'I-SMT': ['annealing', 'gel', 'plasma', 'hydrothermal', 'annealed', 'vapor'], 'I-APL': ['coatings', 'coating', 'solar', 'cells', 'electrode', 'applications', 'electrodes', 'catalysts', 'cathode'], 'I-SPL': ['cubic', 'hexagonal', 'rock', 'ch']}
BertForMaskedLM(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31097, 768)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (cls): BertOnlyMLMHead(
    (predictions): BertLMPredictionHead(
      (transform): BertPredictionHeadTransform(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (transform_act_fn): GELUActivation()
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      )
      (decoder): Linear(in_features=768, out_features=31097, bias=True)
    )
  )
)
tensor([31090, 31091, 31092, 31093, 31094, 31095, 31096], device='cuda:0')
  0%|          | 0/540 [00:00<?, ?it/s]  0%|          | 2/540 [00:00<00:35, 15.00it/s]  1%|          | 5/540 [00:00<00:23, 22.50it/s]  1%|â–         | 8/540 [00:00<00:21, 24.92it/s]  2%|â–         | 11/540 [00:00<00:23, 22.82it/s]  3%|â–Ž         | 14/540 [00:00<00:25, 20.72it/s]  3%|â–Ž         | 17/540 [00:00<00:26, 19.60it/s]  4%|â–Ž         | 20/540 [00:00<00:26, 19.83it/s]  4%|â–         | 23/540 [00:01<00:25, 20.06it/s]  5%|â–         | 26/540 [00:01<00:31, 16.31it/s]  5%|â–Œ         | 28/540 [00:01<00:34, 14.89it/s]  6%|â–Œ         | 30/540 [00:01<00:36, 13.81it/s]  6%|â–Œ         | 32/540 [00:01<00:38, 13.13it/s]  6%|â–‹         | 34/540 [00:02<00:39, 12.88it/s]  7%|â–‹         | 36/540 [00:02<00:40, 12.57it/s]  7%|â–‹         | 38/540 [00:02<00:41, 12.20it/s]  7%|â–‹         | 40/540 [00:02<00:40, 12.23it/s]  8%|â–Š         | 42/540 [00:02<00:41, 11.93it/s]  8%|â–Š         | 44/540 [00:02<00:42, 11.81it/s]  9%|â–Š         | 46/540 [00:03<00:41, 11.92it/s]  9%|â–‰         | 48/540 [00:03<00:40, 12.05it/s]  9%|â–‰         | 50/540 [00:03<00:41, 11.77it/s] 10%|â–‰         | 52/540 [00:03<00:41, 11.65it/s] 10%|â–ˆ         | 54/540 [00:03<00:41, 11.57it/s] 10%|â–ˆ         | 56/540 [00:03<00:41, 11.57it/s] 11%|â–ˆ         | 58/540 [00:04<00:41, 11.66it/s] 11%|â–ˆ         | 60/540 [00:04<00:40, 11.81it/s] 11%|â–ˆâ–        | 62/540 [00:04<00:41, 11.57it/s] 12%|â–ˆâ–        | 64/540 [00:04<00:41, 11.56it/s] 12%|â–ˆâ–        | 66/540 [00:04<00:41, 11.53it/s] 13%|â–ˆâ–Ž        | 68/540 [00:04<00:40, 11.56it/s] 13%|â–ˆâ–Ž        | 70/540 [00:05<00:40, 11.75it/s] 13%|â–ˆâ–Ž        | 72/540 [00:05<00:39, 11.80it/s] 14%|â–ˆâ–Ž        | 74/540 [00:05<00:40, 11.49it/s] 14%|â–ˆâ–        | 76/540 [00:05<00:40, 11.55it/s] 14%|â–ˆâ–        | 78/540 [00:05<00:39, 11.55it/s] 15%|â–ˆâ–        | 80/540 [00:06<00:39, 11.53it/s] 15%|â–ˆâ–Œ        | 82/540 [00:06<00:39, 11.61it/s] 16%|â–ˆâ–Œ        | 84/540 [00:06<00:39, 11.63it/s] 16%|â–ˆâ–Œ        | 86/540 [00:06<00:38, 11.69it/s] 16%|â–ˆâ–‹        | 88/540 [00:06<00:38, 11.71it/s] 17%|â–ˆâ–‹        | 90/540 [00:06<00:38, 11.84it/s] 17%|â–ˆâ–‹        | 92/540 [00:07<00:38, 11.50it/s] 17%|â–ˆâ–‹        | 94/540 [00:07<00:37, 11.76it/s] 18%|â–ˆâ–Š        | 96/540 [00:07<00:37, 11.84it/s] 18%|â–ˆâ–Š        | 98/540 [00:07<00:37, 11.91it/s] 19%|â–ˆâ–Š        | 100/540 [00:07<00:37, 11.72it/s] 19%|â–ˆâ–‰        | 102/540 [00:07<00:37, 11.65it/s] 19%|â–ˆâ–‰        | 104/540 [00:08<00:37, 11.57it/s] 20%|â–ˆâ–‰        | 106/540 [00:08<00:36, 11.75it/s] 20%|â–ˆâ–ˆ        | 108/540 [00:08<00:36, 11.87it/s] 20%|â–ˆâ–ˆ        | 110/540 [00:08<00:36, 11.92it/s] 21%|â–ˆâ–ˆ        | 112/540 [00:08<00:36, 11.73it/s] 21%|â–ˆâ–ˆ        | 114/540 [00:08<00:37, 11.51it/s] 21%|â–ˆâ–ˆâ–       | 116/540 [00:09<00:36, 11.56it/s] 22%|â–ˆâ–ˆâ–       | 118/540 [00:09<00:36, 11.44it/s] 22%|â–ˆâ–ˆâ–       | 120/540 [00:09<00:35, 11.70it/s] 23%|â–ˆâ–ˆâ–Ž       | 122/540 [00:09<00:36, 11.61it/s] 23%|â–ˆâ–ˆâ–Ž       | 124/540 [00:09<00:36, 11.35it/s] 23%|â–ˆâ–ˆâ–Ž       | 126/540 [00:09<00:35, 11.51it/s] 24%|â–ˆâ–ˆâ–Ž       | 128/540 [00:10<00:36, 11.44it/s] 24%|â–ˆâ–ˆâ–       | 130/540 [00:10<00:35, 11.46it/s] 24%|â–ˆâ–ˆâ–       | 132/540 [00:10<00:34, 11.96it/s] 25%|â–ˆâ–ˆâ–       | 134/540 [00:10<00:34, 11.70it/s] 25%|â–ˆâ–ˆâ–Œ       | 136/540 [00:10<00:34, 11.61it/s] 26%|â–ˆâ–ˆâ–Œ       | 138/540 [00:10<00:34, 11.67it/s] 26%|â–ˆâ–ˆâ–Œ       | 140/540 [00:11<00:34, 11.68it/s] 26%|â–ˆâ–ˆâ–‹       | 142/540 [00:11<00:33, 11.85it/s] 27%|â–ˆâ–ˆâ–‹       | 144/540 [00:11<00:32, 12.08it/s] 27%|â–ˆâ–ˆâ–‹       | 146/540 [00:11<00:32, 11.96it/s] 27%|â–ˆâ–ˆâ–‹       | 148/540 [00:11<00:33, 11.72it/s] 28%|â–ˆâ–ˆâ–Š       | 150/540 [00:12<00:33, 11.69it/s] 28%|â–ˆâ–ˆâ–Š       | 152/540 [00:12<00:33, 11.61it/s] 29%|â–ˆâ–ˆâ–Š       | 154/540 [00:12<00:32, 11.72it/s] 29%|â–ˆâ–ˆâ–‰       | 156/540 [00:12<00:33, 11.63it/s] 29%|â–ˆâ–ˆâ–‰       | 158/540 [00:12<00:32, 11.60it/s] 30%|â–ˆâ–ˆâ–‰       | 160/540 [00:12<00:33, 11.45it/s] 30%|â–ˆâ–ˆâ–ˆ       | 162/540 [00:13<00:32, 11.48it/s] 30%|â–ˆâ–ˆâ–ˆ       | 164/540 [00:13<00:32, 11.52it/s] 31%|â–ˆâ–ˆâ–ˆ       | 166/540 [00:13<00:31, 11.73it/s] 31%|â–ˆâ–ˆâ–ˆ       | 168/540 [00:13<00:31, 11.93it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 170/540 [00:13<00:31, 11.61it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 172/540 [00:13<00:31, 11.63it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 174/540 [00:14<00:31, 11.67it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 176/540 [00:14<00:31, 11.70it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 178/540 [00:14<00:30, 11.83it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 180/540 [00:14<00:29, 12.03it/s] 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 182/540 [00:14<00:30, 11.87it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 184/540 [00:14<00:30, 11.63it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 186/540 [00:15<00:30, 11.75it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 188/540 [00:15<00:29, 11.74it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 190/540 [00:15<00:29, 11.83it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 192/540 [00:15<00:29, 11.82it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 194/540 [00:15<00:29, 11.66it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 196/540 [00:15<00:29, 11.53it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 198/540 [00:16<00:29, 11.71it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 200/540 [00:16<00:29, 11.53it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 202/540 [00:16<00:28, 11.67it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 204/540 [00:16<00:28, 11.87it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 206/540 [00:16<00:28, 11.58it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 208/540 [00:16<00:28, 11.63it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 210/540 [00:17<00:28, 11.73it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 212/540 [00:17<00:28, 11.54it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 214/540 [00:17<00:28, 11.56it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 216/540 [00:17<00:27, 11.74it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 218/540 [00:17<00:28, 11.50it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 220/540 [00:17<00:27, 11.77it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 222/540 [00:18<00:27, 11.61it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 224/540 [00:18<00:27, 11.56it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 226/540 [00:18<00:27, 11.60it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 228/540 [00:18<00:26, 11.79it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 230/540 [00:18<00:26, 11.82it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 232/540 [00:19<00:26, 11.82it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 234/540 [00:19<00:25, 11.80it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 236/540 [00:19<00:25, 11.76it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 238/540 [00:19<00:25, 11.71it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 240/540 [00:19<00:25, 11.87it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 242/540 [00:19<00:25, 11.86it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 244/540 [00:20<00:25, 11.72it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 246/540 [00:20<00:25, 11.53it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 248/540 [00:20<00:25, 11.44it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 250/540 [00:20<00:24, 11.68it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 252/540 [00:20<00:24, 11.89it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 254/540 [00:20<00:23, 11.95it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 256/540 [00:21<00:24, 11.78it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 258/540 [00:21<00:23, 11.84it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 260/540 [00:21<00:23, 11.71it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 262/540 [00:21<00:23, 11.82it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 264/540 [00:21<00:23, 11.91it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 266/540 [00:21<00:23, 11.91it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 268/540 [00:22<00:22, 11.86it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 270/540 [00:22<00:23, 11.71it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 272/540 [00:22<00:23, 11.57it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 274/540 [00:22<00:22, 11.93it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 276/540 [00:22<00:22, 11.71it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 278/540 [00:22<00:22, 11.65it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 280/540 [00:23<00:22, 11.48it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 282/540 [00:23<00:22, 11.37it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 284/540 [00:23<00:22, 11.49it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 286/540 [00:23<00:21, 11.61it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 288/540 [00:23<00:21, 11.81it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 290/540 [00:23<00:21, 11.67it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 292/540 [00:24<00:21, 11.53it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 294/540 [00:24<00:21, 11.24it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 296/540 [00:24<00:21, 11.52it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 298/540 [00:24<00:20, 11.74it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 300/540 [00:24<00:20, 11.82it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 302/540 [00:25<00:20, 11.60it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 304/540 [00:25<00:20, 11.73it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 306/540 [00:25<00:20, 11.51it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 308/540 [00:25<00:20, 11.53it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 310/540 [00:25<00:19, 11.80it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 312/540 [00:25<00:19, 11.75it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 314/540 [00:26<00:19, 11.81it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 316/540 [00:26<00:19, 11.64it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 318/540 [00:26<00:19, 11.58it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 320/540 [00:26<00:19, 11.51it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 322/540 [00:26<00:18, 11.72it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 324/540 [00:26<00:18, 11.78it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 326/540 [00:27<00:18, 11.66it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 328/540 [00:27<00:18, 11.48it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 330/540 [00:27<00:18, 11.61it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 332/540 [00:27<00:17, 11.56it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 334/540 [00:27<00:17, 11.71it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 336/540 [00:27<00:17, 11.66it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 338/540 [00:28<00:17, 11.50it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 340/540 [00:28<00:17, 11.53it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 342/540 [00:28<00:17, 11.54it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 344/540 [00:28<00:16, 11.62it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 346/540 [00:28<00:16, 11.57it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 348/540 [00:28<00:16, 11.61it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 350/540 [00:29<00:16, 11.64it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 352/540 [00:29<00:16, 11.64it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 354/540 [00:29<00:16, 11.55it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 356/540 [00:29<00:15, 11.58it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 358/540 [00:29<00:15, 11.58it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 360/540 [00:29<00:15, 11.81it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 362/540 [00:30<00:14, 11.87it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 364/540 [00:30<00:14, 11.87it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 366/540 [00:30<00:14, 11.68it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 368/540 [00:30<00:14, 11.58it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 370/540 [00:30<00:14, 11.57it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 372/540 [00:31<00:14, 11.78it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 374/540 [00:31<00:14, 11.85it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 376/540 [00:31<00:13, 11.77it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 378/540 [00:31<00:13, 11.77it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 380/540 [00:31<00:13, 11.63it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 382/540 [00:31<00:13, 11.90it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 384/540 [00:32<00:13, 11.86it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 386/540 [00:32<00:13, 11.79it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 388/540 [00:32<00:13, 11.65it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 390/540 [00:32<00:12, 11.61it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 392/540 [00:32<00:12, 11.47it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 394/540 [00:32<00:12, 11.50it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 396/540 [00:33<00:12, 11.81it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 398/540 [00:33<00:11, 11.89it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 400/540 [00:33<00:12, 11.62it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 402/540 [00:33<00:11, 11.69it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 404/540 [00:33<00:11, 11.57it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 406/540 [00:33<00:11, 11.78it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 408/540 [00:34<00:11, 11.69it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 410/540 [00:34<00:11, 11.78it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 412/540 [00:34<00:11, 11.53it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 414/540 [00:34<00:10, 11.63it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 416/540 [00:34<00:10, 11.78it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 418/540 [00:34<00:10, 11.81it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 420/540 [00:35<00:10, 11.92it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 422/540 [00:35<00:09, 11.82it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 424/540 [00:35<00:09, 11.71it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 426/540 [00:35<00:09, 11.56it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 428/540 [00:35<00:09, 11.64it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 430/540 [00:35<00:09, 11.64it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 432/540 [00:36<00:09, 11.75it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 434/540 [00:36<00:09, 11.55it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 436/540 [00:36<00:09, 11.48it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 438/540 [00:36<00:08, 11.57it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 440/540 [00:36<00:08, 11.63it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 442/540 [00:36<00:08, 11.92it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 444/540 [00:37<00:08, 11.95it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 446/540 [00:37<00:07, 11.78it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 448/540 [00:37<00:08, 11.47it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 450/540 [00:37<00:07, 11.67it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 452/540 [00:37<00:07, 11.57it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 454/540 [00:38<00:07, 11.62it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 456/540 [00:38<00:07, 11.74it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 458/540 [00:38<00:07, 11.63it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 460/540 [00:38<00:06, 11.63it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 462/540 [00:38<00:06, 11.56it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 464/540 [00:38<00:06, 11.33it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 466/540 [00:39<00:06, 11.56it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 468/540 [00:39<00:06, 11.83it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 470/540 [00:39<00:06, 11.62it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 472/540 [00:39<00:05, 11.88it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 474/540 [00:39<00:05, 11.67it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 476/540 [00:39<00:05, 11.47it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 478/540 [00:40<00:05, 11.69it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 480/540 [00:40<00:05, 11.70it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 482/540 [00:40<00:05, 11.59it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 484/540 [00:40<00:04, 11.71it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 486/540 [00:40<00:04, 11.53it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 488/540 [00:40<00:04, 11.57it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 490/540 [00:41<00:04, 11.62it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 492/540 [00:41<00:04, 11.73it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 494/540 [00:41<00:03, 11.71it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 496/540 [00:41<00:03, 11.45it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 498/540 [00:41<00:03, 11.59it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 500/540 [00:41<00:03, 11.54it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 502/540 [00:42<00:03, 11.60it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 504/540 [00:42<00:03, 11.71it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 506/540 [00:42<00:02, 11.80it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 508/540 [00:42<00:02, 11.54it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 510/540 [00:42<00:02, 11.55it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 512/540 [00:43<00:02, 11.65it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 514/540 [00:43<00:02, 11.62it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 516/540 [00:43<00:02, 11.93it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 518/540 [00:43<00:01, 11.56it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 520/540 [00:43<00:01, 11.49it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 522/540 [00:43<00:01, 11.58it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 524/540 [00:44<00:01, 11.54it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 526/540 [00:44<00:01, 11.52it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 528/540 [00:44<00:01, 11.83it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 530/540 [00:44<00:00, 11.74it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 532/540 [00:44<00:00, 11.59it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 534/540 [00:44<00:00, 11.57it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 536/540 [00:45<00:00, 11.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 538/540 [00:45<00:00, 11.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:45<00:00, 11.78it/s]/home/liwentao/miniconda3/envs/py38/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:48<00:00, 11.22it/s]
Decoding time: 2.681809425354004s
APL_precision: 0.2558139534883721, APL_recall: 0.12941176470588237, APL_f1: 0.17187500000000003, APL_number: 170
CMT_precision: 0.6031746031746031, CMT_recall: 0.38974358974358975, CMT_f1: 0.47352024922118374, CMT_number: 195
DSC_precision: 0.4894366197183099, DSC_recall: 0.3180778032036613, DSC_f1: 0.3855755894590846, DSC_number: 437
MAT_precision: 0.6354581673306773, MAT_recall: 0.46774193548387094, MAT_f1: 0.5388513513513513, MAT_number: 682
PRO_precision: 0.0, PRO_recall: 0.0, PRO_f1: 0.0, PRO_number: 771
SMT_precision: 0.23972602739726026, SMT_recall: 0.2046783625730994, SMT_f1: 0.22082018927444794, SMT_number: 171
SPL_precision: 0.525, SPL_recall: 0.28, SPL_f1: 0.3652173913043478, SPL_number: 75
overall_precision: 0.5168918918918919, overall_recall: 0.24470211915233905, overall_f1: 0.33215739484396195, overall_accuracy: 0.7603459366735759
Finish training, best metric: 
{'APL_precision': 0.2558139534883721, 'APL_recall': 0.12941176470588237, 'APL_f1': 0.17187500000000003, 'APL_number': 170, 'CMT_precision': 0.6031746031746031, 'CMT_recall': 0.38974358974358975, 'CMT_f1': 0.47352024922118374, 'CMT_number': 195, 'DSC_precision': 0.4894366197183099, 'DSC_recall': 0.3180778032036613, 'DSC_f1': 0.3855755894590846, 'DSC_number': 437, 'MAT_precision': 0.6354581673306773, 'MAT_recall': 0.46774193548387094, 'MAT_f1': 0.5388513513513513, 'MAT_number': 682, 'PRO_precision': 0.0, 'PRO_recall': 0.0, 'PRO_f1': 0.0, 'PRO_number': 771, 'SMT_precision': 0.23972602739726026, 'SMT_recall': 0.2046783625730994, 'SMT_f1': 0.22082018927444794, 'SMT_number': 171, 'SPL_precision': 0.525, 'SPL_recall': 0.28, 'SPL_f1': 0.3652173913043478, 'SPL_number': 75, 'overall_precision': 0.5168918918918919, 'overall_recall': 0.24470211915233905, 'overall_f1': 0.33215739484396195, 'overall_accuracy': 0.7603459366735759}
