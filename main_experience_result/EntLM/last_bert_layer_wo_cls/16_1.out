09/14/2023 09:08:04 - INFO - __main__ - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

loading configuration file /home/liwentao/learn/DecT_Mat_NER/model/config.json
Model config BertConfig {
  "_name_or_path": "/home/liwentao/learn/DecT_Mat_NER/model",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.27.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

loading configuration file /home/liwentao/learn/DecT_Mat_NER/model/config.json
Model config BertConfig {
  "_name_or_path": "/home/liwentao/learn/DecT_Mat_NER/model",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.27.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

loading file vocab.txt
loading file tokenizer.json
loading file added_tokens.json
loading file special_tokens_map.json
loading file tokenizer_config.json
loading configuration file /home/liwentao/learn/DecT_Mat_NER/model/config.json
Model config BertConfig {
  "_name_or_path": "/home/liwentao/learn/DecT_Mat_NER/model",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.27.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

loading weights file /home/liwentao/learn/DecT_Mat_NER/model/pytorch_model.bin
Generate config GenerationConfig {
  "_from_model_config": true,
  "pad_token_id": 0,
  "transformers_version": "4.27.1"
}

All model checkpoint weights were used when initializing BertForMaskedLM.

All the weights of BertForMaskedLM were initialized from the model checkpoint at /home/liwentao/learn/DecT_Mat_NER/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.
Generation config file not found, using a generation config created from the model config.
/home/liwentao/learn/DecT_Mat_NER/baseline2_EntLM/train_transformer.py:561: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric("./seqeval_metric.py")
09/14/2023 09:08:15 - INFO - __main__ - ***** Running training *****
09/14/2023 09:08:15 - INFO - __main__ -   Num examples = 41
09/14/2023 09:08:15 - INFO - __main__ -   Num Epochs = 60
09/14/2023 09:08:15 - INFO - __main__ -   Instantaneous batch size per device = 4
09/14/2023 09:08:15 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4
09/14/2023 09:08:15 - INFO - __main__ -   Gradient Accumulation steps = 1
09/14/2023 09:08:15 - INFO - __main__ -   Total optimization steps = 660
Loading label map from scripts/matsciner/final_verbalizer.json...
{'I-CMT': ['electron', 'diffraction', 'microscopy', 'spectroscopy', 'transmission', 'test'], 'I-MAT': ['oxide', 'silicon', 'carbon', 'graphene', 'aluminum', 'oxides'], 'I-DSC': ['films', 'doped', 'thin', 'film', 'alloy'], 'I-PRO': ['properties', 'structure', 'magnetic', 'band', 'conductivity', 'electrical'], 'I-SMT': ['annealing', 'gel', 'plasma', 'hydrothermal', 'annealed', 'vapor'], 'I-APL': ['coatings', 'coating', 'solar', 'cells', 'electrode', 'applications', 'electrodes', 'catalysts', 'cathode'], 'I-SPL': ['cubic', 'hexagonal', 'rock', 'ch']}
{'O': 0, 'I-CMT': 1, 'I-MAT': 2, 'I-DSC': 3, 'I-PRO': 4, 'I-SMT': 5, 'I-APL': 6, 'I-SPL': 7, 'B-CMT': 8, 'B-MAT': 9, 'B-DSC': 10, 'B-PRO': 11, 'B-SMT': 12, 'B-APL': 13, 'B-SPL': 14}
I-CMT
[3081, 10314, 5820, 7779, 2856, 856]
I-MAT
[6678, 8605, 3473, 11106, 15028, 20464]
I-DSC
[7423, 21155, 5197, 5796, 15937]
I-PRO
[1784, 1187, 3510, 2102, 9370, 4874]
I-SMT
[12040, 4051, 2780, 29973, 27202, 12766]
I-APL
[20189, 9754, 6911, 576, 6665, 2040, 8438, 15834, 19112]
I-SPL
[13879, 22235, 8863, 249]
{'I-CMT': ['electron', 'diffraction', 'microscopy', 'spectroscopy', 'transmission', 'test'], 'I-MAT': ['oxide', 'silicon', 'carbon', 'graphene', 'aluminum', 'oxides'], 'I-DSC': ['films', 'doped', 'thin', 'film', 'alloy'], 'I-PRO': ['properties', 'structure', 'magnetic', 'band', 'conductivity', 'electrical'], 'I-SMT': ['annealing', 'gel', 'plasma', 'hydrothermal', 'annealed', 'vapor'], 'I-APL': ['coatings', 'coating', 'solar', 'cells', 'electrode', 'applications', 'electrodes', 'catalysts', 'cathode'], 'I-SPL': ['cubic', 'hexagonal', 'rock', 'ch']}
BertForMaskedLM(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31097, 768)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (cls): BertOnlyMLMHead(
    (predictions): BertLMPredictionHead(
      (transform): BertPredictionHeadTransform(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (transform_act_fn): GELUActivation()
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      )
      (decoder): Linear(in_features=768, out_features=31097, bias=True)
    )
  )
)
tensor([31090, 31091, 31092, 31093, 31094, 31095, 31096], device='cuda:0')
  0%|          | 0/660 [00:00<?, ?it/s]  0%|          | 2/660 [00:00<00:43, 14.96it/s]  1%|          | 4/660 [00:00<00:37, 17.29it/s]  1%|          | 6/660 [00:00<00:37, 17.52it/s]  1%|          | 8/660 [00:00<00:37, 17.32it/s]  2%|▏         | 10/660 [00:00<00:36, 17.77it/s]  2%|▏         | 12/660 [00:00<00:39, 16.43it/s]  2%|▏         | 14/660 [00:00<00:38, 16.92it/s]  2%|▏         | 16/660 [00:00<00:42, 15.04it/s]  3%|▎         | 18/660 [00:01<00:46, 13.71it/s]  3%|▎         | 20/660 [00:01<00:49, 12.94it/s]  3%|▎         | 22/660 [00:01<00:51, 12.47it/s]  4%|▎         | 24/660 [00:01<00:51, 12.32it/s]  4%|▍         | 26/660 [00:01<00:51, 12.36it/s]  4%|▍         | 28/660 [00:02<00:53, 11.86it/s]  5%|▍         | 30/660 [00:02<00:52, 11.97it/s]  5%|▍         | 32/660 [00:02<00:52, 11.98it/s]  5%|▌         | 34/660 [00:02<00:53, 11.64it/s]  5%|▌         | 36/660 [00:02<00:52, 11.84it/s]  6%|▌         | 38/660 [00:02<00:51, 11.96it/s]  6%|▌         | 40/660 [00:03<00:52, 11.79it/s]  6%|▋         | 42/660 [00:03<00:53, 11.61it/s]  7%|▋         | 44/660 [00:03<00:52, 11.63it/s]  7%|▋         | 46/660 [00:03<00:52, 11.64it/s]  7%|▋         | 48/660 [00:03<00:53, 11.52it/s]  8%|▊         | 50/660 [00:03<00:52, 11.71it/s]  8%|▊         | 52/660 [00:04<00:52, 11.68it/s]  8%|▊         | 54/660 [00:04<00:52, 11.60it/s]  8%|▊         | 56/660 [00:04<00:51, 11.63it/s]  9%|▉         | 58/660 [00:04<00:52, 11.51it/s]  9%|▉         | 60/660 [00:04<00:50, 11.78it/s]  9%|▉         | 62/660 [00:04<00:51, 11.68it/s] 10%|▉         | 64/660 [00:05<00:50, 11.71it/s] 10%|█         | 66/660 [00:05<00:52, 11.41it/s] 10%|█         | 68/660 [00:05<00:50, 11.70it/s] 11%|█         | 70/660 [00:05<00:51, 11.46it/s] 11%|█         | 72/660 [00:05<00:50, 11.63it/s] 11%|█         | 74/660 [00:05<00:50, 11.58it/s] 12%|█▏        | 76/660 [00:06<00:50, 11.62it/s] 12%|█▏        | 78/660 [00:06<00:49, 11.71it/s] 12%|█▏        | 80/660 [00:06<00:49, 11.70it/s] 12%|█▏        | 82/660 [00:06<00:49, 11.59it/s] 13%|█▎        | 84/660 [00:06<00:49, 11.66it/s] 13%|█▎        | 86/660 [00:06<00:48, 11.81it/s] 13%|█▎        | 88/660 [00:07<00:48, 11.84it/s] 14%|█▎        | 90/660 [00:07<00:48, 11.84it/s] 14%|█▍        | 92/660 [00:07<00:48, 11.71it/s] 14%|█▍        | 94/660 [00:07<00:48, 11.75it/s] 15%|█▍        | 96/660 [00:07<00:48, 11.61it/s] 15%|█▍        | 98/660 [00:08<00:47, 11.82it/s] 15%|█▌        | 100/660 [00:08<00:46, 11.96it/s] 15%|█▌        | 102/660 [00:08<00:47, 11.71it/s] 16%|█▌        | 104/660 [00:08<00:47, 11.72it/s] 16%|█▌        | 106/660 [00:08<00:48, 11.43it/s] 16%|█▋        | 108/660 [00:08<00:48, 11.44it/s] 17%|█▋        | 110/660 [00:09<00:47, 11.62it/s] 17%|█▋        | 112/660 [00:09<00:47, 11.61it/s] 17%|█▋        | 114/660 [00:09<00:47, 11.57it/s] 18%|█▊        | 116/660 [00:09<00:47, 11.56it/s] 18%|█▊        | 118/660 [00:09<00:47, 11.52it/s] 18%|█▊        | 120/660 [00:09<00:46, 11.53it/s] 18%|█▊        | 122/660 [00:10<00:45, 11.71it/s] 19%|█▉        | 124/660 [00:10<00:45, 11.73it/s] 19%|█▉        | 126/660 [00:10<00:45, 11.68it/s] 19%|█▉        | 128/660 [00:10<00:45, 11.58it/s] 20%|█▉        | 130/660 [00:10<00:45, 11.59it/s] 20%|██        | 132/660 [00:10<00:44, 11.78it/s] 20%|██        | 134/660 [00:11<00:43, 11.97it/s] 21%|██        | 136/660 [00:11<00:44, 11.90it/s] 21%|██        | 138/660 [00:11<00:44, 11.78it/s] 21%|██        | 140/660 [00:11<00:44, 11.69it/s] 22%|██▏       | 142/660 [00:11<00:44, 11.67it/s] 22%|██▏       | 144/660 [00:11<00:43, 11.88it/s] 22%|██▏       | 146/660 [00:12<00:44, 11.62it/s] 22%|██▏       | 148/660 [00:12<00:44, 11.60it/s] 23%|██▎       | 150/660 [00:12<00:44, 11.53it/s] 23%|██▎       | 152/660 [00:12<00:44, 11.39it/s] 23%|██▎       | 154/660 [00:12<00:44, 11.39it/s] 24%|██▎       | 156/660 [00:12<00:42, 11.80it/s] 24%|██▍       | 158/660 [00:13<00:42, 11.69it/s] 24%|██▍       | 160/660 [00:13<00:43, 11.59it/s] 25%|██▍       | 162/660 [00:13<00:42, 11.71it/s] 25%|██▍       | 164/660 [00:13<00:42, 11.56it/s] 25%|██▌       | 166/660 [00:13<00:41, 11.79it/s] 25%|██▌       | 168/660 [00:14<00:41, 11.97it/s] 26%|██▌       | 170/660 [00:14<00:41, 11.88it/s] 26%|██▌       | 172/660 [00:14<00:40, 12.01it/s] 26%|██▋       | 174/660 [00:14<00:41, 11.65it/s] 27%|██▋       | 176/660 [00:14<00:41, 11.67it/s] 27%|██▋       | 178/660 [00:14<00:41, 11.66it/s] 27%|██▋       | 180/660 [00:15<00:40, 11.75it/s] 28%|██▊       | 182/660 [00:15<00:41, 11.61it/s] 28%|██▊       | 184/660 [00:15<00:40, 11.80it/s] 28%|██▊       | 186/660 [00:15<00:40, 11.76it/s] 28%|██▊       | 188/660 [00:15<00:40, 11.71it/s] 29%|██▉       | 190/660 [00:15<00:40, 11.51it/s] 29%|██▉       | 192/660 [00:16<00:40, 11.68it/s] 29%|██▉       | 194/660 [00:16<00:39, 11.78it/s] 30%|██▉       | 196/660 [00:16<00:39, 11.64it/s] 30%|███       | 198/660 [00:16<00:39, 11.66it/s] 30%|███       | 200/660 [00:16<00:39, 11.68it/s] 31%|███       | 202/660 [00:16<00:39, 11.61it/s] 31%|███       | 204/660 [00:17<00:39, 11.68it/s] 31%|███       | 206/660 [00:17<00:39, 11.56it/s] 32%|███▏      | 208/660 [00:17<00:38, 11.75it/s] 32%|███▏      | 210/660 [00:17<00:38, 11.65it/s] 32%|███▏      | 212/660 [00:17<00:39, 11.47it/s] 32%|███▏      | 214/660 [00:17<00:38, 11.57it/s] 33%|███▎      | 216/660 [00:18<00:37, 11.70it/s] 33%|███▎      | 218/660 [00:18<00:37, 11.74it/s] 33%|███▎      | 220/660 [00:18<00:37, 11.79it/s] 34%|███▎      | 222/660 [00:18<00:37, 11.80it/s] 34%|███▍      | 224/660 [00:18<00:37, 11.75it/s] 34%|███▍      | 226/660 [00:18<00:37, 11.70it/s] 35%|███▍      | 228/660 [00:19<00:36, 11.74it/s] 35%|███▍      | 230/660 [00:19<00:36, 11.82it/s] 35%|███▌      | 232/660 [00:19<00:36, 11.84it/s] 35%|███▌      | 234/660 [00:19<00:36, 11.68it/s] 36%|███▌      | 236/660 [00:19<00:36, 11.55it/s] 36%|███▌      | 238/660 [00:20<00:36, 11.57it/s] 36%|███▋      | 240/660 [00:20<00:35, 11.69it/s] 37%|███▋      | 242/660 [00:20<00:35, 11.83it/s] 37%|███▋      | 244/660 [00:20<00:35, 11.86it/s] 37%|███▋      | 246/660 [00:20<00:34, 11.95it/s] 38%|███▊      | 248/660 [00:20<00:34, 11.79it/s] 38%|███▊      | 250/660 [00:21<00:34, 11.72it/s] 38%|███▊      | 252/660 [00:21<00:34, 11.82it/s] 38%|███▊      | 254/660 [00:21<00:33, 12.08it/s] 39%|███▉      | 256/660 [00:21<00:34, 11.85it/s] 39%|███▉      | 258/660 [00:21<00:34, 11.79it/s] 39%|███▉      | 260/660 [00:21<00:34, 11.70it/s] 40%|███▉      | 262/660 [00:22<00:34, 11.56it/s] 40%|████      | 264/660 [00:22<00:33, 11.69it/s] 40%|████      | 266/660 [00:22<00:33, 11.80it/s] 41%|████      | 268/660 [00:22<00:33, 11.69it/s] 41%|████      | 270/660 [00:22<00:33, 11.48it/s] 41%|████      | 272/660 [00:22<00:33, 11.52it/s] 42%|████▏     | 274/660 [00:23<00:33, 11.40it/s] 42%|████▏     | 276/660 [00:23<00:32, 11.68it/s] 42%|████▏     | 278/660 [00:23<00:32, 11.70it/s] 42%|████▏     | 280/660 [00:23<00:31, 11.89it/s] 43%|████▎     | 282/660 [00:23<00:32, 11.56it/s] 43%|████▎     | 284/660 [00:23<00:33, 11.24it/s] 43%|████▎     | 286/660 [00:24<00:32, 11.42it/s] 44%|████▎     | 288/660 [00:24<00:31, 11.67it/s] 44%|████▍     | 290/660 [00:24<00:31, 11.87it/s] 44%|████▍     | 292/660 [00:24<00:31, 11.65it/s] 45%|████▍     | 294/660 [00:24<00:31, 11.54it/s] 45%|████▍     | 296/660 [00:24<00:31, 11.62it/s] 45%|████▌     | 298/660 [00:25<00:31, 11.60it/s] 45%|████▌     | 300/660 [00:25<00:30, 11.61it/s] 46%|████▌     | 302/660 [00:25<00:30, 11.81it/s] 46%|████▌     | 304/660 [00:25<00:30, 11.68it/s] 46%|████▋     | 306/660 [00:25<00:30, 11.66it/s] 47%|████▋     | 308/660 [00:25<00:30, 11.69it/s] 47%|████▋     | 310/660 [00:26<00:30, 11.58it/s] 47%|████▋     | 312/660 [00:26<00:29, 11.81it/s] 48%|████▊     | 314/660 [00:26<00:29, 11.68it/s] 48%|████▊     | 316/660 [00:26<00:29, 11.66it/s] 48%|████▊     | 318/660 [00:26<00:29, 11.56it/s] 48%|████▊     | 320/660 [00:27<00:29, 11.62it/s] 49%|████▉     | 322/660 [00:27<00:28, 11.69it/s] 49%|████▉     | 324/660 [00:27<00:29, 11.58it/s] 49%|████▉     | 326/660 [00:27<00:28, 11.83it/s] 50%|████▉     | 328/660 [00:27<00:28, 11.52it/s] 50%|█████     | 330/660 [00:27<00:28, 11.47it/s] 50%|█████     | 332/660 [00:28<00:28, 11.46it/s] 51%|█████     | 334/660 [00:28<00:28, 11.41it/s] 51%|█████     | 336/660 [00:28<00:27, 11.59it/s] 51%|█████     | 338/660 [00:28<00:27, 11.66it/s] 52%|█████▏    | 340/660 [00:28<00:27, 11.66it/s] 52%|█████▏    | 342/660 [00:28<00:27, 11.75it/s] 52%|█████▏    | 344/660 [00:29<00:27, 11.60it/s] 52%|█████▏    | 346/660 [00:29<00:27, 11.58it/s] 53%|█████▎    | 348/660 [00:29<00:26, 11.66it/s] 53%|█████▎    | 350/660 [00:29<00:26, 11.61it/s] 53%|█████▎    | 352/660 [00:29<00:26, 11.78it/s] 54%|█████▎    | 354/660 [00:29<00:25, 11.88it/s] 54%|█████▍    | 356/660 [00:30<00:25, 11.73it/s] 54%|█████▍    | 358/660 [00:30<00:26, 11.60it/s] 55%|█████▍    | 360/660 [00:30<00:25, 11.66it/s] 55%|█████▍    | 362/660 [00:30<00:25, 11.76it/s] 55%|█████▌    | 364/660 [00:30<00:24, 11.95it/s] 55%|█████▌    | 366/660 [00:30<00:25, 11.70it/s] 56%|█████▌    | 368/660 [00:31<00:24, 11.71it/s] 56%|█████▌    | 370/660 [00:31<00:24, 11.69it/s] 56%|█████▋    | 372/660 [00:31<00:24, 11.77it/s] 57%|█████▋    | 374/660 [00:31<00:24, 11.79it/s] 57%|█████▋    | 376/660 [00:31<00:23, 11.84it/s] 57%|█████▋    | 378/660 [00:31<00:24, 11.68it/s] 58%|█████▊    | 380/660 [00:32<00:24, 11.56it/s] 58%|█████▊    | 382/660 [00:32<00:24, 11.54it/s] 58%|█████▊    | 384/660 [00:32<00:23, 11.55it/s] 58%|█████▊    | 386/660 [00:32<00:23, 11.65it/s] 59%|█████▉    | 388/660 [00:32<00:23, 11.75it/s] 59%|█████▉    | 390/660 [00:33<00:22, 11.87it/s] 59%|█████▉    | 392/660 [00:33<00:23, 11.64it/s] 60%|█████▉    | 394/660 [00:33<00:22, 11.70it/s] 60%|██████    | 396/660 [00:33<00:22, 11.64it/s] 60%|██████    | 398/660 [00:33<00:22, 11.69it/s] 61%|██████    | 400/660 [00:33<00:22, 11.69it/s] 61%|██████    | 402/660 [00:34<00:22, 11.63it/s] 61%|██████    | 404/660 [00:34<00:22, 11.59it/s] 62%|██████▏   | 406/660 [00:34<00:21, 11.60it/s] 62%|██████▏   | 408/660 [00:34<00:21, 11.87it/s] 62%|██████▏   | 410/660 [00:34<00:21, 11.87it/s] 62%|██████▏   | 412/660 [00:34<00:20, 11.85it/s] 63%|██████▎   | 414/660 [00:35<00:21, 11.71it/s] 63%|██████▎   | 416/660 [00:35<00:20, 11.65it/s] 63%|██████▎   | 418/660 [00:35<00:20, 11.56it/s] 64%|██████▎   | 420/660 [00:35<00:20, 11.68it/s] 64%|██████▍   | 422/660 [00:35<00:20, 11.86it/s] 64%|██████▍   | 424/660 [00:35<00:20, 11.67it/s] 65%|██████▍   | 426/660 [00:36<00:20, 11.43it/s] 65%|██████▍   | 428/660 [00:36<00:20, 11.48it/s] 65%|██████▌   | 430/660 [00:36<00:19, 11.64it/s] 65%|██████▌   | 432/660 [00:36<00:19, 11.73it/s] 66%|██████▌   | 434/660 [00:36<00:18, 11.91it/s] 66%|██████▌   | 436/660 [00:36<00:18, 11.81it/s] 66%|██████▋   | 438/660 [00:37<00:19, 11.62it/s] 67%|██████▋   | 440/660 [00:37<00:18, 11.58it/s] 67%|██████▋   | 442/660 [00:37<00:18, 11.70it/s] 67%|██████▋   | 444/660 [00:37<00:18, 11.64it/s] 68%|██████▊   | 446/660 [00:37<00:18, 11.65it/s] 68%|██████▊   | 448/660 [00:37<00:18, 11.69it/s] 68%|██████▊   | 450/660 [00:38<00:18, 11.58it/s] 68%|██████▊   | 452/660 [00:38<00:17, 11.65it/s] 69%|██████▉   | 454/660 [00:38<00:18, 11.44it/s] 69%|██████▉   | 456/660 [00:38<00:17, 11.46it/s] 69%|██████▉   | 458/660 [00:38<00:17, 11.63it/s] 70%|██████▉   | 460/660 [00:39<00:16, 11.91it/s] 70%|███████   | 462/660 [00:39<00:16, 11.66it/s] 70%|███████   | 464/660 [00:39<00:16, 11.75it/s] 71%|███████   | 466/660 [00:39<00:16, 11.52it/s] 71%|███████   | 468/660 [00:39<00:16, 11.53it/s] 71%|███████   | 470/660 [00:39<00:16, 11.61it/s] 72%|███████▏  | 472/660 [00:40<00:16, 11.64it/s] 72%|███████▏  | 474/660 [00:40<00:15, 11.71it/s] 72%|███████▏  | 476/660 [00:40<00:16, 11.45it/s] 72%|███████▏  | 478/660 [00:40<00:15, 11.61it/s] 73%|███████▎  | 480/660 [00:40<00:15, 11.67it/s] 73%|███████▎  | 482/660 [00:40<00:15, 11.78it/s] 73%|███████▎  | 484/660 [00:41<00:14, 11.76it/s] 74%|███████▎  | 486/660 [00:41<00:14, 11.63it/s] 74%|███████▍  | 488/660 [00:41<00:14, 11.62it/s] 74%|███████▍  | 490/660 [00:41<00:14, 11.48it/s] 75%|███████▍  | 492/660 [00:41<00:14, 11.55it/s] 75%|███████▍  | 494/660 [00:41<00:14, 11.70it/s] 75%|███████▌  | 496/660 [00:42<00:14, 11.71it/s] 75%|███████▌  | 498/660 [00:42<00:13, 11.67it/s] 76%|███████▌  | 500/660 [00:42<00:13, 11.45it/s] 76%|███████▌  | 502/660 [00:42<00:13, 11.48it/s] 76%|███████▋  | 504/660 [00:42<00:13, 11.65it/s] 77%|███████▋  | 506/660 [00:42<00:13, 11.80it/s] 77%|███████▋  | 508/660 [00:43<00:12, 11.86it/s] 77%|███████▋  | 510/660 [00:43<00:12, 11.55it/s] 78%|███████▊  | 512/660 [00:43<00:12, 11.51it/s] 78%|███████▊  | 514/660 [00:43<00:12, 11.51it/s] 78%|███████▊  | 516/660 [00:43<00:12, 11.58it/s] 78%|███████▊  | 518/660 [00:43<00:11, 11.90it/s] 79%|███████▉  | 520/660 [00:44<00:11, 11.81it/s] 79%|███████▉  | 522/660 [00:44<00:11, 11.60it/s] 79%|███████▉  | 524/660 [00:44<00:11, 11.40it/s] 80%|███████▉  | 526/660 [00:44<00:11, 11.41it/s] 80%|████████  | 528/660 [00:44<00:11, 11.49it/s] 80%|████████  | 530/660 [00:45<00:11, 11.73it/s] 81%|████████  | 532/660 [00:45<00:10, 11.72it/s] 81%|████████  | 534/660 [00:45<00:10, 11.80it/s] 81%|████████  | 536/660 [00:45<00:10, 11.85it/s] 82%|████████▏ | 538/660 [00:45<00:10, 11.72it/s] 82%|████████▏ | 540/660 [00:45<00:10, 11.96it/s] 82%|████████▏ | 542/660 [00:46<00:10, 11.39it/s] 82%|████████▏ | 544/660 [00:46<00:10, 11.33it/s] 83%|████████▎ | 546/660 [00:46<00:09, 11.52it/s] 83%|████████▎ | 548/660 [00:46<00:09, 11.41it/s] 83%|████████▎ | 550/660 [00:46<00:09, 11.24it/s] 84%|████████▎ | 552/660 [00:46<00:09, 11.69it/s] 84%|████████▍ | 554/660 [00:47<00:09, 11.62it/s] 84%|████████▍ | 556/660 [00:47<00:08, 11.70it/s] 85%|████████▍ | 558/660 [00:47<00:08, 11.42it/s] 85%|████████▍ | 560/660 [00:47<00:08, 11.37it/s] 85%|████████▌ | 562/660 [00:47<00:08, 12.15it/s] 85%|████████▌ | 564/660 [00:47<00:07, 12.86it/s] 86%|████████▌ | 566/660 [00:48<00:07, 13.43it/s] 86%|████████▌ | 568/660 [00:48<00:06, 13.36it/s] 86%|████████▋ | 570/660 [00:48<00:06, 13.88it/s] 87%|████████▋ | 572/660 [00:48<00:06, 14.03it/s] 87%|████████▋ | 574/660 [00:48<00:06, 14.24it/s] 87%|████████▋ | 576/660 [00:48<00:05, 14.29it/s] 88%|████████▊ | 578/660 [00:48<00:05, 14.44it/s] 88%|████████▊ | 580/660 [00:49<00:05, 14.64it/s] 88%|████████▊ | 582/660 [00:49<00:05, 14.52it/s] 88%|████████▊ | 584/660 [00:49<00:05, 14.83it/s] 89%|████████▉ | 586/660 [00:49<00:05, 14.48it/s] 89%|████████▉ | 588/660 [00:49<00:04, 14.76it/s] 89%|████████▉ | 590/660 [00:49<00:04, 14.68it/s] 90%|████████▉ | 592/660 [00:49<00:04, 14.82it/s] 90%|█████████ | 594/660 [00:49<00:04, 14.72it/s] 90%|█████████ | 596/660 [00:50<00:04, 14.76it/s] 91%|█████████ | 598/660 [00:50<00:04, 14.81it/s] 91%|█████████ | 600/660 [00:50<00:04, 14.92it/s] 91%|█████████ | 602/660 [00:50<00:03, 14.81it/s] 92%|█████████▏| 604/660 [00:50<00:03, 14.94it/s] 92%|█████████▏| 606/660 [00:50<00:03, 14.91it/s] 92%|█████████▏| 608/660 [00:50<00:03, 14.65it/s] 92%|█████████▏| 610/660 [00:51<00:03, 14.45it/s] 93%|█████████▎| 612/660 [00:51<00:03, 14.50it/s] 93%|█████████▎| 614/660 [00:51<00:03, 14.78it/s] 93%|█████████▎| 616/660 [00:51<00:02, 14.76it/s] 94%|█████████▎| 618/660 [00:51<00:02, 14.70it/s] 94%|█████████▍| 620/660 [00:51<00:02, 14.48it/s] 94%|█████████▍| 622/660 [00:51<00:02, 14.44it/s] 95%|█████████▍| 624/660 [00:52<00:02, 14.57it/s] 95%|█████████▍| 626/660 [00:52<00:02, 14.64it/s] 95%|█████████▌| 628/660 [00:52<00:02, 14.58it/s] 95%|█████████▌| 630/660 [00:52<00:02, 14.37it/s] 96%|█████████▌| 632/660 [00:52<00:01, 14.47it/s] 96%|█████████▌| 634/660 [00:52<00:01, 14.23it/s] 96%|█████████▋| 636/660 [00:52<00:01, 14.31it/s] 97%|█████████▋| 638/660 [00:52<00:01, 14.48it/s] 97%|█████████▋| 640/660 [00:53<00:01, 14.63it/s] 97%|█████████▋| 642/660 [00:53<00:01, 14.31it/s] 98%|█████████▊| 644/660 [00:53<00:01, 14.29it/s] 98%|█████████▊| 646/660 [00:53<00:00, 14.31it/s] 98%|█████████▊| 648/660 [00:53<00:00, 14.66it/s] 98%|█████████▊| 650/660 [00:53<00:00, 14.71it/s] 99%|█████████▉| 652/660 [00:53<00:00, 14.74it/s] 99%|█████████▉| 654/660 [00:54<00:00, 14.59it/s] 99%|█████████▉| 656/660 [00:54<00:00, 14.75it/s]100%|█████████▉| 658/660 [00:54<00:00, 14.34it/s]100%|██████████| 660/660 [00:54<00:00, 14.69it/s]/home/liwentao/miniconda3/envs/py38/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
100%|██████████| 660/660 [00:56<00:00, 11.68it/s]
Decoding time: 2.0275790691375732s
APL_precision: 0.37735849056603776, APL_recall: 0.23529411764705882, APL_f1: 0.2898550724637681, APL_number: 170
CMT_precision: 0.6666666666666666, CMT_recall: 0.41025641025641024, CMT_f1: 0.5079365079365079, CMT_number: 195
DSC_precision: 0.5933014354066986, DSC_recall: 0.2837528604118993, DSC_f1: 0.38390092879256965, DSC_number: 437
MAT_precision: 0.6119402985074627, MAT_recall: 0.5410557184750733, MAT_f1: 0.5743190661478599, MAT_number: 682
PRO_precision: 0.0, PRO_recall: 0.0, PRO_f1: 0.0, PRO_number: 771
SMT_precision: 0.41134751773049644, SMT_recall: 0.3391812865497076, SMT_f1: 0.37179487179487175, SMT_number: 171
SPL_precision: 0.5384615384615384, SPL_recall: 0.28, SPL_f1: 0.3684210526315789, SPL_number: 75
overall_precision: 0.5681444991789819, overall_recall: 0.27668932427029186, overall_f1: 0.372143049206776, overall_accuracy: 0.7733542991923379
Finish training, best metric: 
{'APL_precision': 0.37735849056603776, 'APL_recall': 0.23529411764705882, 'APL_f1': 0.2898550724637681, 'APL_number': 170, 'CMT_precision': 0.6666666666666666, 'CMT_recall': 0.41025641025641024, 'CMT_f1': 0.5079365079365079, 'CMT_number': 195, 'DSC_precision': 0.5933014354066986, 'DSC_recall': 0.2837528604118993, 'DSC_f1': 0.38390092879256965, 'DSC_number': 437, 'MAT_precision': 0.6119402985074627, 'MAT_recall': 0.5410557184750733, 'MAT_f1': 0.5743190661478599, 'MAT_number': 682, 'PRO_precision': 0.0, 'PRO_recall': 0.0, 'PRO_f1': 0.0, 'PRO_number': 771, 'SMT_precision': 0.41134751773049644, 'SMT_recall': 0.3391812865497076, 'SMT_f1': 0.37179487179487175, 'SMT_number': 171, 'SPL_precision': 0.5384615384615384, 'SPL_recall': 0.28, 'SPL_f1': 0.3684210526315789, 'SPL_number': 75, 'overall_precision': 0.5681444991789819, 'overall_recall': 0.27668932427029186, 'overall_f1': 0.372143049206776, 'overall_accuracy': 0.7733542991923379}
