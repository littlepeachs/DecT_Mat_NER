09/14/2023 08:52:23 - INFO - __main__ - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

loading configuration file /home/liwentao/learn/DecT_Mat_NER/model/config.json
Model config BertConfig {
  "_name_or_path": "/home/liwentao/learn/DecT_Mat_NER/model",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.27.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

loading configuration file /home/liwentao/learn/DecT_Mat_NER/model/config.json
Model config BertConfig {
  "_name_or_path": "/home/liwentao/learn/DecT_Mat_NER/model",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.27.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

loading file vocab.txt
loading file tokenizer.json
loading file added_tokens.json
loading file special_tokens_map.json
loading file tokenizer_config.json
loading configuration file /home/liwentao/learn/DecT_Mat_NER/model/config.json
Model config BertConfig {
  "_name_or_path": "/home/liwentao/learn/DecT_Mat_NER/model",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.27.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

loading weights file /home/liwentao/learn/DecT_Mat_NER/model/pytorch_model.bin
Generate config GenerationConfig {
  "_from_model_config": true,
  "pad_token_id": 0,
  "transformers_version": "4.27.1"
}

All model checkpoint weights were used when initializing BertForMaskedLM.

All the weights of BertForMaskedLM were initialized from the model checkpoint at /home/liwentao/learn/DecT_Mat_NER/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.
Generation config file not found, using a generation config created from the model config.
/home/liwentao/learn/DecT_Mat_NER/baseline2_EntLM/train_transformer.py:569: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric("./seqeval_metric.py")
09/14/2023 08:52:36 - INFO - __main__ - ***** Running training *****
09/14/2023 08:52:36 - INFO - __main__ -   Num examples = 21
09/14/2023 08:52:36 - INFO - __main__ -   Num Epochs = 60
09/14/2023 08:52:36 - INFO - __main__ -   Instantaneous batch size per device = 4
09/14/2023 08:52:36 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4
09/14/2023 08:52:36 - INFO - __main__ -   Gradient Accumulation steps = 1
09/14/2023 08:52:36 - INFO - __main__ -   Total optimization steps = 360
Loading label map from scripts/matsciner/final_verbalizer.json...
{'I-CMT': ['electron', 'diffraction', 'microscopy', 'spectroscopy', 'transmission', 'test'], 'I-MAT': ['oxide', 'silicon', 'carbon', 'graphene', 'aluminum', 'oxides'], 'I-DSC': ['films', 'doped', 'thin', 'film', 'alloy'], 'I-PRO': ['properties', 'structure', 'magnetic', 'band', 'conductivity', 'electrical'], 'I-SMT': ['annealing', 'gel', 'plasma', 'hydrothermal', 'annealed', 'vapor'], 'I-APL': ['coatings', 'coating', 'solar', 'cells', 'electrode', 'applications', 'electrodes', 'catalysts', 'cathode'], 'I-SPL': ['cubic', 'hexagonal', 'rock', 'ch']}
{'O': 0, 'I-CMT': 1, 'I-MAT': 2, 'I-DSC': 3, 'I-PRO': 4, 'I-SMT': 5, 'I-APL': 6, 'I-SPL': 7, 'B-CMT': 8, 'B-MAT': 9, 'B-DSC': 10, 'B-PRO': 11, 'B-SMT': 12, 'B-APL': 13, 'B-SPL': 14}
I-CMT
[3081, 10314, 5820, 7779, 2856, 856]
I-MAT
[6678, 8605, 3473, 11106, 15028, 20464]
I-DSC
[7423, 21155, 5197, 5796, 15937]
I-PRO
[1784, 1187, 3510, 2102, 9370, 4874]
I-SMT
[12040, 4051, 2780, 29973, 27202, 12766]
I-APL
[20189, 9754, 6911, 576, 6665, 2040, 8438, 15834, 19112]
I-SPL
[13879, 22235, 8863, 249]
{'I-CMT': ['electron', 'diffraction', 'microscopy', 'spectroscopy', 'transmission', 'test'], 'I-MAT': ['oxide', 'silicon', 'carbon', 'graphene', 'aluminum', 'oxides'], 'I-DSC': ['films', 'doped', 'thin', 'film', 'alloy'], 'I-PRO': ['properties', 'structure', 'magnetic', 'band', 'conductivity', 'electrical'], 'I-SMT': ['annealing', 'gel', 'plasma', 'hydrothermal', 'annealed', 'vapor'], 'I-APL': ['coatings', 'coating', 'solar', 'cells', 'electrode', 'applications', 'electrodes', 'catalysts', 'cathode'], 'I-SPL': ['cubic', 'hexagonal', 'rock', 'ch']}
BertForMaskedLM(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(31097, 768)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
  (cls): BertOnlyMLMHead(
    (predictions): BertLMPredictionHead(
      (transform): BertPredictionHeadTransform(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (transform_act_fn): GELUActivation()
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      )
      (decoder): Linear(in_features=768, out_features=31097, bias=True)
    )
  )
)
tensor([31090, 31091, 31092, 31093, 31094, 31095, 31096], device='cuda:0')
  0%|          | 0/360 [00:00<?, ?it/s]  0%|          | 1/360 [00:00<00:52,  6.90it/s]  1%|          | 3/360 [00:00<00:36,  9.90it/s]  1%|          | 4/360 [00:00<00:36,  9.87it/s]  1%|▏         | 5/360 [00:00<00:36,  9.69it/s]  2%|▏         | 6/360 [00:00<00:39,  8.98it/s]  2%|▏         | 8/360 [00:00<00:35,  9.96it/s]  2%|▎         | 9/360 [00:00<00:35,  9.84it/s]  3%|▎         | 10/360 [00:01<00:35,  9.87it/s]  3%|▎         | 11/360 [00:01<00:35,  9.73it/s]  3%|▎         | 12/360 [00:01<00:35,  9.69it/s]  4%|▎         | 13/360 [00:01<00:35,  9.70it/s]  4%|▍         | 14/360 [00:01<00:36,  9.50it/s]  4%|▍         | 15/360 [00:01<00:36,  9.50it/s]  4%|▍         | 16/360 [00:01<00:35,  9.60it/s]  5%|▍         | 17/360 [00:01<00:35,  9.68it/s]  5%|▌         | 19/360 [00:01<00:34,  9.85it/s]  6%|▌         | 20/360 [00:02<00:35,  9.68it/s]  6%|▌         | 21/360 [00:02<00:35,  9.66it/s]  6%|▌         | 22/360 [00:02<00:35,  9.61it/s]  7%|▋         | 24/360 [00:02<00:34,  9.87it/s]  7%|▋         | 26/360 [00:02<00:33,  9.86it/s]  8%|▊         | 27/360 [00:02<00:34,  9.75it/s]  8%|▊         | 28/360 [00:02<00:34,  9.75it/s]  8%|▊         | 29/360 [00:03<00:34,  9.58it/s]  9%|▊         | 31/360 [00:03<00:32, 10.00it/s]  9%|▉         | 32/360 [00:03<00:33,  9.73it/s]  9%|▉         | 34/360 [00:03<00:33,  9.69it/s] 10%|▉         | 35/360 [00:03<00:33,  9.69it/s] 10%|█         | 37/360 [00:03<00:32,  9.89it/s] 11%|█         | 38/360 [00:03<00:32,  9.79it/s] 11%|█         | 39/360 [00:04<00:32,  9.74it/s] 11%|█         | 40/360 [00:04<00:33,  9.56it/s] 11%|█▏        | 41/360 [00:04<00:33,  9.61it/s] 12%|█▏        | 43/360 [00:04<00:32,  9.86it/s] 12%|█▏        | 44/360 [00:04<00:32,  9.74it/s] 12%|█▎        | 45/360 [00:04<00:32,  9.72it/s] 13%|█▎        | 46/360 [00:04<00:32,  9.73it/s] 13%|█▎        | 47/360 [00:04<00:32,  9.75it/s] 13%|█▎        | 48/360 [00:04<00:31,  9.80it/s] 14%|█▍        | 50/360 [00:05<00:31,  9.73it/s] 14%|█▍        | 51/360 [00:05<00:31,  9.68it/s] 14%|█▍        | 52/360 [00:05<00:31,  9.67it/s] 15%|█▍        | 53/360 [00:05<00:32,  9.51it/s] 15%|█▌        | 55/360 [00:05<00:30, 10.05it/s] 16%|█▌        | 56/360 [00:05<00:30,  9.94it/s] 16%|█▌        | 57/360 [00:05<00:30,  9.78it/s] 16%|█▌        | 58/360 [00:05<00:31,  9.72it/s] 16%|█▋        | 59/360 [00:06<00:30,  9.72it/s] 17%|█▋        | 60/360 [00:06<00:33,  9.04it/s] 17%|█▋        | 62/360 [00:06<00:29, 10.13it/s] 18%|█▊        | 63/360 [00:06<00:29, 10.01it/s] 18%|█▊        | 64/360 [00:06<00:30,  9.82it/s] 18%|█▊        | 65/360 [00:06<00:30,  9.71it/s] 18%|█▊        | 66/360 [00:06<00:30,  9.71it/s] 19%|█▉        | 68/360 [00:07<00:30,  9.65it/s] 19%|█▉        | 69/360 [00:07<00:30,  9.58it/s] 19%|█▉        | 70/360 [00:07<00:30,  9.63it/s] 20%|█▉        | 71/360 [00:07<00:30,  9.56it/s] 20%|██        | 73/360 [00:07<00:28,  9.95it/s] 21%|██        | 74/360 [00:07<00:29,  9.84it/s] 21%|██        | 75/360 [00:07<00:28,  9.84it/s] 21%|██        | 76/360 [00:07<00:29,  9.76it/s] 21%|██▏       | 77/360 [00:07<00:29,  9.74it/s] 22%|██▏       | 79/360 [00:08<00:27, 10.16it/s] 22%|██▎       | 81/360 [00:08<00:28,  9.79it/s] 23%|██▎       | 82/360 [00:08<00:28,  9.77it/s] 23%|██▎       | 83/360 [00:08<00:28,  9.72it/s] 24%|██▎       | 85/360 [00:08<00:27, 10.05it/s] 24%|██▍       | 86/360 [00:08<00:28,  9.78it/s] 24%|██▍       | 87/360 [00:08<00:28,  9.67it/s] 25%|██▍       | 89/360 [00:09<00:27,  9.75it/s] 25%|██▌       | 91/360 [00:09<00:27,  9.93it/s] 26%|██▌       | 92/360 [00:09<00:27,  9.83it/s] 26%|██▌       | 93/360 [00:09<00:27,  9.82it/s] 26%|██▌       | 94/360 [00:09<00:27,  9.77it/s] 26%|██▋       | 95/360 [00:09<00:27,  9.71it/s] 27%|██▋       | 97/360 [00:09<00:26, 10.02it/s] 27%|██▋       | 98/360 [00:10<00:26,  9.87it/s] 28%|██▊       | 99/360 [00:10<00:26,  9.79it/s] 28%|██▊       | 100/360 [00:10<00:26,  9.80it/s] 28%|██▊       | 101/360 [00:10<00:26,  9.78it/s] 29%|██▊       | 103/360 [00:10<00:25, 10.13it/s] 29%|██▉       | 104/360 [00:10<00:25,  9.93it/s] 29%|██▉       | 105/360 [00:10<00:26,  9.79it/s] 30%|██▉       | 107/360 [00:10<00:25,  9.89it/s] 30%|███       | 109/360 [00:11<00:24, 10.08it/s] 31%|███       | 110/360 [00:11<00:25,  9.92it/s] 31%|███       | 111/360 [00:11<00:25,  9.74it/s] 31%|███▏      | 113/360 [00:11<00:25,  9.77it/s] 32%|███▏      | 115/360 [00:11<00:24, 10.00it/s] 32%|███▏      | 116/360 [00:11<00:24,  9.81it/s] 32%|███▎      | 117/360 [00:11<00:25,  9.70it/s] 33%|███▎      | 118/360 [00:12<00:24,  9.75it/s] 33%|███▎      | 119/360 [00:12<00:24,  9.76it/s] 33%|███▎      | 120/360 [00:12<00:24,  9.78it/s] 34%|███▍      | 122/360 [00:12<00:24,  9.88it/s] 34%|███▍      | 124/360 [00:12<00:23,  9.85it/s] 35%|███▍      | 125/360 [00:12<00:23,  9.83it/s] 35%|███▌      | 127/360 [00:12<00:23, 10.12it/s] 36%|███▌      | 129/360 [00:13<00:23,  9.99it/s] 36%|███▌      | 130/360 [00:13<00:23,  9.92it/s] 36%|███▋      | 131/360 [00:13<00:23,  9.84it/s] 37%|███▋      | 133/360 [00:13<00:22,  9.95it/s] 37%|███▋      | 134/360 [00:13<00:22,  9.86it/s] 38%|███▊      | 135/360 [00:13<00:22,  9.84it/s] 38%|███▊      | 136/360 [00:13<00:23,  9.61it/s] 38%|███▊      | 138/360 [00:14<00:22,  9.73it/s] 39%|███▉      | 140/360 [00:14<00:22,  9.69it/s] 39%|███▉      | 142/360 [00:14<00:22,  9.62it/s] 40%|███▉      | 143/360 [00:14<00:22,  9.51it/s] 40%|████      | 145/360 [00:14<00:22,  9.71it/s] 41%|████      | 147/360 [00:15<00:21,  9.85it/s] 41%|████      | 148/360 [00:15<00:21,  9.71it/s] 41%|████▏     | 149/360 [00:15<00:21,  9.74it/s] 42%|████▏     | 151/360 [00:15<00:21,  9.84it/s] 42%|████▏     | 152/360 [00:15<00:21,  9.79it/s] 42%|████▎     | 153/360 [00:15<00:21,  9.79it/s] 43%|████▎     | 154/360 [00:15<00:21,  9.48it/s] 43%|████▎     | 155/360 [00:15<00:21,  9.45it/s] 44%|████▎     | 157/360 [00:16<00:20,  9.80it/s] 44%|████▍     | 158/360 [00:16<00:20,  9.77it/s] 44%|████▍     | 159/360 [00:16<00:20,  9.61it/s] 44%|████▍     | 160/360 [00:16<00:20,  9.53it/s] 45%|████▌     | 162/360 [00:16<00:20,  9.89it/s] 46%|████▌     | 164/360 [00:16<00:19,  9.90it/s] 46%|████▌     | 165/360 [00:16<00:19,  9.82it/s] 46%|████▌     | 166/360 [00:16<00:19,  9.77it/s] 46%|████▋     | 167/360 [00:17<00:19,  9.76it/s] 47%|████▋     | 168/360 [00:17<00:19,  9.77it/s] 47%|████▋     | 170/360 [00:17<00:19,  9.86it/s] 48%|████▊     | 171/360 [00:17<00:19,  9.78it/s] 48%|████▊     | 172/360 [00:17<00:19,  9.65it/s] 48%|████▊     | 174/360 [00:17<00:19,  9.72it/s] 49%|████▉     | 176/360 [00:18<00:18,  9.93it/s] 49%|████▉     | 177/360 [00:18<00:18,  9.68it/s] 49%|████▉     | 178/360 [00:18<00:18,  9.68it/s] 50%|████▉     | 179/360 [00:18<00:18,  9.66it/s] 50%|█████     | 181/360 [00:18<00:18,  9.92it/s] 51%|█████     | 182/360 [00:18<00:18,  9.79it/s] 51%|█████     | 183/360 [00:18<00:18,  9.77it/s] 51%|█████     | 184/360 [00:18<00:18,  9.48it/s] 52%|█████▏    | 186/360 [00:19<00:17,  9.71it/s] 52%|█████▏    | 188/360 [00:19<00:17,  9.85it/s] 52%|█████▎    | 189/360 [00:19<00:17,  9.70it/s] 53%|█████▎    | 190/360 [00:19<00:17,  9.51it/s] 53%|█████▎    | 192/360 [00:19<00:17,  9.69it/s] 54%|█████▎    | 193/360 [00:19<00:17,  9.74it/s] 54%|█████▍    | 194/360 [00:19<00:17,  9.76it/s] 54%|█████▍    | 195/360 [00:19<00:17,  9.69it/s] 54%|█████▍    | 196/360 [00:20<00:17,  9.64it/s] 55%|█████▍    | 197/360 [00:20<00:17,  9.58it/s] 55%|█████▌    | 199/360 [00:20<00:15, 10.11it/s] 56%|█████▌    | 200/360 [00:20<00:16,  9.87it/s] 56%|█████▌    | 201/360 [00:20<00:16,  9.73it/s] 56%|█████▌    | 202/360 [00:20<00:16,  9.75it/s] 56%|█████▋    | 203/360 [00:20<00:16,  9.74it/s] 57%|█████▋    | 204/360 [00:20<00:15,  9.78it/s] 57%|█████▋    | 206/360 [00:21<00:15,  9.92it/s] 57%|█████▊    | 207/360 [00:21<00:15,  9.72it/s] 58%|█████▊    | 208/360 [00:21<00:15,  9.70it/s] 58%|█████▊    | 209/360 [00:21<00:15,  9.65it/s] 59%|█████▊    | 211/360 [00:21<00:14, 10.17it/s] 59%|█████▉    | 213/360 [00:21<00:14,  9.86it/s] 59%|█████▉    | 214/360 [00:21<00:15,  9.66it/s] 60%|█████▉    | 215/360 [00:22<00:15,  9.56it/s] 60%|██████    | 217/360 [00:22<00:14,  9.83it/s] 61%|██████    | 218/360 [00:22<00:14,  9.78it/s] 61%|██████    | 219/360 [00:22<00:14,  9.64it/s] 61%|██████    | 220/360 [00:22<00:14,  9.68it/s] 61%|██████▏   | 221/360 [00:22<00:14,  9.66it/s] 62%|██████▏   | 222/360 [00:22<00:14,  9.72it/s] 62%|██████▏   | 224/360 [00:22<00:13,  9.83it/s] 62%|██████▎   | 225/360 [00:23<00:13,  9.85it/s] 63%|██████▎   | 226/360 [00:23<00:13,  9.83it/s] 63%|██████▎   | 228/360 [00:23<00:13,  9.92it/s] 64%|██████▍   | 230/360 [00:23<00:13,  9.92it/s] 64%|██████▍   | 231/360 [00:23<00:13,  9.90it/s] 64%|██████▍   | 232/360 [00:23<00:13,  9.78it/s] 65%|██████▍   | 233/360 [00:23<00:13,  9.68it/s] 65%|██████▌   | 235/360 [00:24<00:12, 10.03it/s] 66%|██████▌   | 236/360 [00:24<00:12,  9.88it/s] 66%|██████▌   | 237/360 [00:24<00:12,  9.72it/s] 66%|██████▌   | 238/360 [00:24<00:12,  9.64it/s] 66%|██████▋   | 239/360 [00:24<00:12,  9.46it/s] 67%|██████▋   | 241/360 [00:24<00:11, 10.08it/s] 67%|██████▋   | 242/360 [00:24<00:11,  9.94it/s] 68%|██████▊   | 244/360 [00:24<00:11,  9.92it/s] 68%|██████▊   | 245/360 [00:25<00:11,  9.93it/s] 69%|██████▊   | 247/360 [00:25<00:11, 10.01it/s] 69%|██████▉   | 248/360 [00:25<00:11,  9.75it/s] 69%|██████▉   | 249/360 [00:25<00:11,  9.69it/s] 69%|██████▉   | 250/360 [00:25<00:11,  9.64it/s] 70%|██████▉   | 251/360 [00:25<00:11,  9.68it/s] 70%|███████   | 253/360 [00:25<00:10,  9.94it/s] 71%|███████   | 254/360 [00:25<00:10,  9.89it/s] 71%|███████   | 255/360 [00:26<00:10,  9.69it/s] 71%|███████   | 256/360 [00:26<00:10,  9.70it/s] 71%|███████▏  | 257/360 [00:26<00:10,  9.70it/s] 72%|███████▏  | 259/360 [00:26<00:10,  9.83it/s] 72%|███████▏  | 260/360 [00:26<00:10,  9.84it/s] 72%|███████▎  | 261/360 [00:26<00:10,  9.75it/s] 73%|███████▎  | 262/360 [00:26<00:10,  9.70it/s] 73%|███████▎  | 263/360 [00:26<00:10,  9.63it/s] 74%|███████▎  | 265/360 [00:27<00:09, 10.11it/s] 74%|███████▍  | 266/360 [00:27<00:09,  9.86it/s] 74%|███████▍  | 268/360 [00:27<00:09,  9.73it/s] 75%|███████▍  | 269/360 [00:27<00:09,  9.78it/s] 75%|███████▌  | 270/360 [00:27<00:09,  9.79it/s] 76%|███████▌  | 272/360 [00:27<00:08,  9.97it/s] 76%|███████▌  | 273/360 [00:27<00:08,  9.83it/s] 76%|███████▌  | 274/360 [00:28<00:08,  9.70it/s] 76%|███████▋  | 275/360 [00:28<00:08,  9.60it/s] 77%|███████▋  | 277/360 [00:28<00:08,  9.99it/s] 77%|███████▋  | 278/360 [00:28<00:08,  9.60it/s] 78%|███████▊  | 280/360 [00:28<00:08,  9.86it/s] 78%|███████▊  | 281/360 [00:28<00:08,  9.67it/s] 79%|███████▊  | 283/360 [00:28<00:07, 10.06it/s] 79%|███████▉  | 284/360 [00:29<00:07,  9.86it/s] 79%|███████▉  | 285/360 [00:29<00:07,  9.88it/s] 79%|███████▉  | 286/360 [00:29<00:07,  9.67it/s] 80%|████████  | 288/360 [00:29<00:07,  9.94it/s] 81%|████████  | 290/360 [00:29<00:07,  9.99it/s] 81%|████████  | 291/360 [00:29<00:06,  9.93it/s] 81%|████████  | 292/360 [00:29<00:06,  9.79it/s] 81%|████████▏ | 293/360 [00:29<00:06,  9.79it/s] 82%|████████▏ | 295/360 [00:30<00:06, 10.12it/s] 82%|████████▏ | 296/360 [00:30<00:06,  9.93it/s] 82%|████████▎ | 297/360 [00:30<00:06,  9.84it/s] 83%|████████▎ | 298/360 [00:30<00:06,  9.73it/s] 83%|████████▎ | 299/360 [00:30<00:06,  9.70it/s] 84%|████████▎ | 301/360 [00:30<00:05,  9.96it/s] 84%|████████▍ | 302/360 [00:30<00:05,  9.95it/s] 84%|████████▍ | 303/360 [00:30<00:05,  9.69it/s] 84%|████████▍ | 304/360 [00:31<00:05,  9.64it/s] 85%|████████▍ | 305/360 [00:31<00:05,  9.45it/s] 85%|████████▌ | 306/360 [00:31<00:05,  9.59it/s] 86%|████████▌ | 308/360 [00:31<00:05,  9.83it/s] 86%|████████▌ | 309/360 [00:31<00:05,  9.75it/s] 86%|████████▌ | 310/360 [00:31<00:05,  9.62it/s] 86%|████████▋ | 311/360 [00:31<00:05,  9.64it/s] 87%|████████▋ | 313/360 [00:31<00:04,  9.95it/s] 87%|████████▋ | 314/360 [00:32<00:04,  9.79it/s] 88%|████████▊ | 315/360 [00:32<00:04,  9.66it/s] 88%|████████▊ | 316/360 [00:32<00:04,  9.43it/s] 88%|████████▊ | 318/360 [00:32<00:04,  9.94it/s] 89%|████████▉ | 320/360 [00:32<00:04,  9.95it/s] 89%|████████▉ | 321/360 [00:32<00:04,  9.68it/s] 89%|████████▉ | 322/360 [00:32<00:03,  9.65it/s] 90%|████████▉ | 323/360 [00:33<00:03,  9.58it/s] 90%|█████████ | 325/360 [00:33<00:03,  9.82it/s] 91%|█████████ | 327/360 [00:33<00:03,  9.77it/s] 91%|█████████ | 328/360 [00:33<00:03,  9.80it/s] 91%|█████████▏| 329/360 [00:33<00:03,  9.80it/s] 92%|█████████▏| 331/360 [00:33<00:02, 10.03it/s] 92%|█████████▏| 332/360 [00:33<00:02,  9.82it/s] 93%|█████████▎| 334/360 [00:34<00:02, 10.41it/s] 93%|█████████▎| 336/360 [00:34<00:02, 11.27it/s] 94%|█████████▍| 338/360 [00:34<00:01, 11.78it/s] 94%|█████████▍| 340/360 [00:34<00:01, 11.77it/s] 95%|█████████▌| 342/360 [00:34<00:01, 12.27it/s] 96%|█████████▌| 344/360 [00:34<00:01, 12.30it/s] 96%|█████████▌| 346/360 [00:35<00:01, 11.92it/s] 97%|█████████▋| 348/360 [00:35<00:01, 11.26it/s] 97%|█████████▋| 350/360 [00:35<00:00, 11.09it/s] 98%|█████████▊| 352/360 [00:35<00:00, 10.24it/s] 98%|█████████▊| 354/360 [00:35<00:00, 10.04it/s] 99%|█████████▉| 356/360 [00:36<00:00, 10.66it/s] 99%|█████████▉| 358/360 [00:36<00:00, 10.74it/s]100%|██████████| 360/360 [00:36<00:00, 11.33it/s]100%|██████████| 360/360 [00:38<00:00,  9.32it/s]
Decoding time: 2.21622896194458s
APL_precision: 0.48148148148148145, APL_recall: 0.22941176470588234, APL_f1: 0.31075697211155373, APL_number: 170
CMT_precision: 0.10256410256410256, CMT_recall: 0.14358974358974358, CMT_f1: 0.11965811965811965, CMT_number: 195
DSC_precision: 0.41216216216216217, DSC_recall: 0.13958810068649885, DSC_f1: 0.20854700854700853, DSC_number: 437
MAT_precision: 0.579476861167002, MAT_recall: 0.4222873900293255, MAT_f1: 0.48854961832061067, MAT_number: 682
PRO_precision: 0.3763440860215054, PRO_recall: 0.1815823605706874, PRO_f1: 0.24496937882764652, PRO_number: 771
SMT_precision: 0.19383259911894274, SMT_recall: 0.2573099415204678, SMT_f1: 0.22110552763819094, SMT_number: 171
SPL_precision: 0.3148148148148148, SPL_recall: 0.22666666666666666, SPL_f1: 0.2635658914728682, SPL_number: 75
overall_precision: 0.3734866828087167, overall_recall: 0.2467013194722111, overall_f1: 0.29713460149289667, overall_accuracy: 0.7582017010935601
Finish training, best metric: 
{'APL_precision': 0.48148148148148145, 'APL_recall': 0.22941176470588234, 'APL_f1': 0.31075697211155373, 'APL_number': 170, 'CMT_precision': 0.10256410256410256, 'CMT_recall': 0.14358974358974358, 'CMT_f1': 0.11965811965811965, 'CMT_number': 195, 'DSC_precision': 0.41216216216216217, 'DSC_recall': 0.13958810068649885, 'DSC_f1': 0.20854700854700853, 'DSC_number': 437, 'MAT_precision': 0.579476861167002, 'MAT_recall': 0.4222873900293255, 'MAT_f1': 0.48854961832061067, 'MAT_number': 682, 'PRO_precision': 0.3763440860215054, 'PRO_recall': 0.1815823605706874, 'PRO_f1': 0.24496937882764652, 'PRO_number': 771, 'SMT_precision': 0.19383259911894274, 'SMT_recall': 0.2573099415204678, 'SMT_f1': 0.22110552763819094, 'SMT_number': 171, 'SPL_precision': 0.3148148148148148, 'SPL_recall': 0.22666666666666666, 'SPL_f1': 0.2635658914728682, 'SPL_number': 75, 'overall_precision': 0.3734866828087167, 'overall_recall': 0.2467013194722111, 'overall_f1': 0.29713460149289667, 'overall_accuracy': 0.7582017010935601}
