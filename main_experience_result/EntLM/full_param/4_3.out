09/13/2023 11:33:25 - INFO - __main__ - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]Downloading data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 7536.93it/s]
Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]Extracting data files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 482.99it/s]
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 12 examples [00:00, 3002.90 examples/s]
Generating validation split: 0 examples [00:00, ? examples/s]Generating validation split: 546 examples [00:00, 75805.69 examples/s]
loading configuration file /home/liwentao/learn/DecT_Mat_NER/model/config.json
Model config BertConfig {
  "_name_or_path": "/home/liwentao/learn/DecT_Mat_NER/model",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.27.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

loading configuration file /home/liwentao/learn/DecT_Mat_NER/model/config.json
Model config BertConfig {
  "_name_or_path": "/home/liwentao/learn/DecT_Mat_NER/model",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.27.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

loading file vocab.txt
loading file tokenizer.json
loading file added_tokens.json
loading file special_tokens_map.json
loading file tokenizer_config.json
loading configuration file /home/liwentao/learn/DecT_Mat_NER/model/config.json
Model config BertConfig {
  "_name_or_path": "/home/liwentao/learn/DecT_Mat_NER/model",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.27.1",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 31090
}

loading weights file /home/liwentao/learn/DecT_Mat_NER/model/pytorch_model.bin
Generate config GenerationConfig {
  "_from_model_config": true,
  "pad_token_id": 0,
  "transformers_version": "4.27.1"
}

All model checkpoint weights were used when initializing BertForMaskedLM.

All the weights of BertForMaskedLM were initialized from the model checkpoint at /home/liwentao/learn/DecT_Mat_NER/model.
If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForMaskedLM for predictions without further training.
Generation config file not found, using a generation config created from the model config.
Loading label map from scripts/matsciner/final_verbalizer.json...
{'I-CMT': ['electron', 'diffraction', 'microscopy', 'spectroscopy', 'transmission', 'test'], 'I-MAT': ['oxide', 'silicon', 'carbon', 'graphene', 'aluminum', 'oxides'], 'I-DSC': ['films', 'doped', 'thin', 'film', 'alloy'], 'I-PRO': ['properties', 'structure', 'magnetic', 'band', 'conductivity', 'electrical'], 'I-SMT': ['annealing', 'gel', 'plasma', 'hydrothermal', 'annealed', 'vapor'], 'I-APL': ['coatings', 'coating', 'solar', 'cells', 'electrode', 'applications', 'electrodes', 'catalysts', 'cathode'], 'I-SPL': ['cubic', 'hexagonal', 'rock', 'ch']}
{'O': 0, 'I-CMT': 1, 'I-MAT': 2, 'I-DSC': 3, 'I-PRO': 4, 'I-SMT': 5, 'I-APL': 6, 'I-SPL': 7, 'B-CMT': 8, 'B-MAT': 9, 'B-DSC': 10, 'B-PRO': 11, 'B-SMT': 12, 'B-APL': 13, 'B-SPL': 14}
I-CMT
[3081, 10314, 5820, 7779, 2856, 856]
I-MAT
[6678, 8605, 3473, 11106, 15028, 20464]
I-DSC
[7423, 21155, 5197, 5796, 15937]
I-PRO
[1784, 1187, 3510, 2102, 9370, 4874]
I-SMT
[12040, 4051, 2780, 29973, 27202, 12766]
I-APL
[20189, 9754, 6911, 576, 6665, 2040, 8438, 15834, 19112]
I-SPL
[13879, 22235, 8863, 249]
{'I-CMT': ['electron', 'diffraction', 'microscopy', 'spectroscopy', 'transmission', 'test'], 'I-MAT': ['oxide', 'silicon', 'carbon', 'graphene', 'aluminum', 'oxides'], 'I-DSC': ['films', 'doped', 'thin', 'film', 'alloy'], 'I-PRO': ['properties', 'structure', 'magnetic', 'band', 'conductivity', 'electrical'], 'I-SMT': ['annealing', 'gel', 'plasma', 'hydrothermal', 'annealed', 'vapor'], 'I-APL': ['coatings', 'coating', 'solar', 'cells', 'electrode', 'applications', 'electrodes', 'catalysts', 'cathode'], 'I-SPL': ['cubic', 'hexagonal', 'rock', 'ch']}
Running tokenizer on dataset:   0%|          | 0/12 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 942.84 examples/s]
Running tokenizer on dataset:   0%|          | 0/546 [00:00<?, ? examples/s]Running tokenizer on dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 546/546 [00:00<00:00, 3998.61 examples/s]Running tokenizer on dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 546/546 [00:00<00:00, 3893.41 examples/s]
/home/liwentao/learn/DecT_Mat_NER/baseline2_EntLM/train_transformer.py:546: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric("./seqeval_metric.py")
09/13/2023 11:33:37 - INFO - __main__ - ***** Running training *****
09/13/2023 11:33:37 - INFO - __main__ -   Num examples = 12
09/13/2023 11:33:37 - INFO - __main__ -   Num Epochs = 60
09/13/2023 11:33:37 - INFO - __main__ -   Instantaneous batch size per device = 4
09/13/2023 11:33:37 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4
09/13/2023 11:33:37 - INFO - __main__ -   Gradient Accumulation steps = 1
09/13/2023 11:33:37 - INFO - __main__ -   Total optimization steps = 180
tensor([31090, 31091, 31092, 31093, 31094, 31095, 31096], device='cuda:0')
  0%|          | 0/180 [00:00<?, ?it/s]  1%|          | 1/180 [00:00<00:28,  6.21it/s]  1%|          | 2/180 [00:00<00:26,  6.63it/s]  2%|â–         | 3/180 [00:00<00:24,  7.21it/s]  2%|â–         | 4/180 [00:00<00:23,  7.45it/s]  3%|â–Ž         | 5/180 [00:00<00:24,  7.01it/s]  3%|â–Ž         | 6/180 [00:00<00:25,  6.89it/s]  4%|â–         | 7/180 [00:01<00:25,  6.89it/s]  4%|â–         | 8/180 [00:01<00:25,  6.83it/s]  5%|â–Œ         | 9/180 [00:01<00:24,  7.01it/s]  6%|â–Œ         | 10/180 [00:01<00:24,  6.86it/s]  6%|â–Œ         | 11/180 [00:01<00:24,  6.84it/s]  7%|â–‹         | 12/180 [00:01<00:24,  6.91it/s]  7%|â–‹         | 13/180 [00:01<00:24,  6.92it/s]  8%|â–Š         | 14/180 [00:02<00:23,  6.97it/s]  8%|â–Š         | 15/180 [00:02<00:23,  7.10it/s]  9%|â–‰         | 16/180 [00:02<00:23,  7.01it/s]  9%|â–‰         | 17/180 [00:02<00:23,  6.94it/s] 10%|â–ˆ         | 18/180 [00:02<00:22,  7.08it/s] 11%|â–ˆ         | 19/180 [00:02<00:22,  7.01it/s] 11%|â–ˆ         | 20/180 [00:02<00:23,  6.80it/s] 12%|â–ˆâ–        | 21/180 [00:03<00:23,  6.85it/s] 12%|â–ˆâ–        | 22/180 [00:03<00:22,  6.98it/s] 13%|â–ˆâ–Ž        | 23/180 [00:03<00:22,  7.01it/s] 13%|â–ˆâ–Ž        | 24/180 [00:03<00:22,  7.06it/s] 14%|â–ˆâ–        | 25/180 [00:03<00:22,  6.94it/s] 14%|â–ˆâ–        | 26/180 [00:03<00:22,  6.91it/s] 15%|â–ˆâ–Œ        | 27/180 [00:03<00:22,  6.86it/s] 16%|â–ˆâ–Œ        | 28/180 [00:04<00:22,  6.82it/s] 16%|â–ˆâ–Œ        | 29/180 [00:04<00:22,  6.77it/s] 17%|â–ˆâ–‹        | 30/180 [00:04<00:22,  6.81it/s] 17%|â–ˆâ–‹        | 31/180 [00:04<00:21,  6.97it/s] 18%|â–ˆâ–Š        | 32/180 [00:04<00:21,  7.03it/s] 18%|â–ˆâ–Š        | 33/180 [00:04<00:21,  6.90it/s] 19%|â–ˆâ–‰        | 34/180 [00:04<00:20,  6.97it/s] 19%|â–ˆâ–‰        | 35/180 [00:05<00:20,  7.06it/s] 20%|â–ˆâ–ˆ        | 36/180 [00:05<00:19,  7.23it/s] 21%|â–ˆâ–ˆ        | 37/180 [00:05<00:20,  6.98it/s] 21%|â–ˆâ–ˆ        | 38/180 [00:05<00:20,  6.94it/s] 22%|â–ˆâ–ˆâ–       | 39/180 [00:05<00:20,  7.00it/s] 22%|â–ˆâ–ˆâ–       | 40/180 [00:05<00:20,  6.84it/s] 23%|â–ˆâ–ˆâ–Ž       | 41/180 [00:05<00:20,  6.94it/s] 23%|â–ˆâ–ˆâ–Ž       | 42/180 [00:06<00:20,  6.84it/s] 24%|â–ˆâ–ˆâ–       | 43/180 [00:06<00:19,  7.04it/s] 24%|â–ˆâ–ˆâ–       | 44/180 [00:06<00:19,  6.83it/s] 25%|â–ˆâ–ˆâ–Œ       | 45/180 [00:06<00:19,  6.93it/s] 26%|â–ˆâ–ˆâ–Œ       | 46/180 [00:06<00:19,  7.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 47/180 [00:06<00:19,  6.82it/s] 27%|â–ˆâ–ˆâ–‹       | 48/180 [00:06<00:18,  6.95it/s] 27%|â–ˆâ–ˆâ–‹       | 49/180 [00:07<00:18,  6.92it/s] 28%|â–ˆâ–ˆâ–Š       | 50/180 [00:07<00:18,  6.88it/s] 28%|â–ˆâ–ˆâ–Š       | 51/180 [00:07<00:18,  6.97it/s] 29%|â–ˆâ–ˆâ–‰       | 52/180 [00:07<00:18,  6.84it/s] 29%|â–ˆâ–ˆâ–‰       | 53/180 [00:07<00:18,  6.86it/s] 30%|â–ˆâ–ˆâ–ˆ       | 54/180 [00:07<00:18,  6.77it/s] 31%|â–ˆâ–ˆâ–ˆ       | 55/180 [00:07<00:18,  6.88it/s] 31%|â–ˆâ–ˆâ–ˆ       | 56/180 [00:08<00:17,  6.96it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 57/180 [00:08<00:17,  6.87it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 58/180 [00:08<00:17,  7.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 59/180 [00:08<00:17,  7.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 60/180 [00:08<00:16,  7.14it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 61/180 [00:08<00:17,  6.92it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 62/180 [00:08<00:16,  6.96it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 63/180 [00:09<00:16,  6.97it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 64/180 [00:09<00:16,  6.92it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 65/180 [00:09<00:16,  7.02it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 66/180 [00:09<00:16,  7.03it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 67/180 [00:09<00:16,  7.03it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 68/180 [00:09<00:15,  7.05it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 69/180 [00:09<00:15,  7.02it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 70/180 [00:10<00:15,  6.94it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 71/180 [00:10<00:15,  6.99it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 72/180 [00:10<00:15,  7.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 73/180 [00:10<00:15,  7.13it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 74/180 [00:10<00:15,  6.99it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 75/180 [00:10<00:14,  7.25it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 76/180 [00:10<00:14,  7.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 77/180 [00:11<00:14,  6.94it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 78/180 [00:11<00:14,  7.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 79/180 [00:11<00:14,  6.92it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 80/180 [00:11<00:14,  7.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 81/180 [00:11<00:14,  7.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 82/180 [00:11<00:14,  6.92it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 83/180 [00:11<00:13,  6.95it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 84/180 [00:12<00:13,  6.91it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 85/180 [00:12<00:13,  6.90it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 86/180 [00:12<00:13,  6.97it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 87/180 [00:12<00:13,  7.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 88/180 [00:12<00:13,  7.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 89/180 [00:12<00:13,  6.97it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 90/180 [00:12<00:12,  7.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 91/180 [00:13<00:12,  7.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 92/180 [00:13<00:12,  6.94it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 93/180 [00:13<00:12,  6.91it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 94/180 [00:13<00:12,  6.87it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 95/180 [00:13<00:12,  6.96it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 96/180 [00:13<00:11,  7.12it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 97/180 [00:13<00:11,  6.94it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 98/180 [00:14<00:11,  6.89it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 99/180 [00:14<00:11,  7.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 100/180 [00:14<00:11,  7.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 101/180 [00:14<00:11,  6.92it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 102/180 [00:14<00:11,  7.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 103/180 [00:14<00:11,  6.87it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 104/180 [00:14<00:11,  6.87it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 105/180 [00:15<00:11,  6.81it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 106/180 [00:15<00:10,  6.85it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 107/180 [00:15<00:10,  6.91it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 108/180 [00:15<00:10,  6.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 109/180 [00:15<00:10,  6.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 110/180 [00:15<00:10,  6.92it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 111/180 [00:15<00:09,  7.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 112/180 [00:16<00:09,  7.15it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 113/180 [00:16<00:09,  6.86it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 114/180 [00:16<00:09,  6.94it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 115/180 [00:16<00:09,  6.86it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 116/180 [00:16<00:09,  6.83it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 117/180 [00:16<00:08,  7.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 118/180 [00:16<00:08,  6.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 119/180 [00:17<00:08,  6.92it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 120/180 [00:17<00:08,  6.95it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 121/180 [00:17<00:08,  6.85it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 122/180 [00:17<00:08,  6.92it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 123/180 [00:17<00:08,  6.99it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 124/180 [00:17<00:07,  7.03it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 125/180 [00:17<00:07,  6.89it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 126/180 [00:18<00:07,  6.94it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 127/180 [00:18<00:07,  6.86it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 128/180 [00:18<00:07,  7.04it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 129/180 [00:18<00:07,  7.04it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 130/180 [00:18<00:07,  6.99it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 131/180 [00:18<00:07,  6.81it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 132/180 [00:18<00:07,  6.82it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 133/180 [00:19<00:06,  6.84it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 134/180 [00:19<00:06,  6.95it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 135/180 [00:19<00:06,  6.87it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 136/180 [00:19<00:06,  6.97it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 137/180 [00:19<00:06,  6.89it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 138/180 [00:19<00:06,  6.93it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 139/180 [00:19<00:05,  7.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 140/180 [00:20<00:05,  7.08it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 141/180 [00:20<00:05,  7.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 142/180 [00:20<00:05,  6.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 143/180 [00:20<00:05,  7.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 144/180 [00:20<00:05,  6.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 145/180 [00:20<00:04,  7.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 146/180 [00:20<00:04,  7.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 147/180 [00:21<00:04,  7.08it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 148/180 [00:21<00:04,  6.92it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 149/180 [00:21<00:04,  6.88it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 150/180 [00:21<00:04,  6.92it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 151/180 [00:21<00:04,  6.87it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 152/180 [00:21<00:03,  7.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 153/180 [00:21<00:03,  6.92it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 154/180 [00:22<00:03,  6.90it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 155/180 [00:22<00:03,  6.94it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 156/180 [00:22<00:03,  7.04it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 157/180 [00:22<00:03,  6.92it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 158/180 [00:22<00:03,  7.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 159/180 [00:22<00:02,  7.07it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 160/180 [00:22<00:02,  7.11it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 161/180 [00:23<00:02,  6.86it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 162/180 [00:23<00:02,  6.94it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 163/180 [00:23<00:02,  7.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 164/180 [00:23<00:02,  6.93it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 165/180 [00:23<00:02,  7.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 166/180 [00:23<00:02,  6.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 167/180 [00:24<00:01,  6.90it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 168/180 [00:24<00:01,  7.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 169/180 [00:24<00:01,  6.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 170/180 [00:24<00:01,  6.94it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 171/180 [00:24<00:01,  7.12it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 172/180 [00:24<00:01,  6.87it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 173/180 [00:24<00:01,  6.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 174/180 [00:25<00:00,  6.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 175/180 [00:25<00:00,  6.89it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 176/180 [00:25<00:00,  6.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 177/180 [00:25<00:00,  7.06it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 178/180 [00:25<00:00,  7.05it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 179/180 [00:25<00:00,  7.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:25<00:00,  6.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:28<00:00,  6.28it/s]
Decoding time: 2.7796497344970703s
APL_precision: 0.4636363636363636, APL_recall: 0.3, APL_f1: 0.3642857142857142, APL_number: 170
CMT_precision: 0.5337837837837838, CMT_recall: 0.40512820512820513, CMT_f1: 0.4606413994169096, CMT_number: 195
DSC_precision: 0.5063291139240507, DSC_recall: 0.2745995423340961, DSC_f1: 0.3560830860534125, DSC_number: 437
MAT_precision: 0.5461309523809523, MAT_recall: 0.5381231671554252, MAT_f1: 0.5420974889217134, MAT_number: 682
PRO_precision: 0.5659340659340659, PRO_recall: 0.13359273670557717, PRO_f1: 0.2161594963273872, PRO_number: 771
SMT_precision: 0.25555555555555554, SMT_recall: 0.13450292397660818, SMT_f1: 0.17624521072796934, SMT_number: 171
SPL_precision: 0.46551724137931033, SPL_recall: 0.36, SPL_f1: 0.40601503759398494, SPL_number: 75
overall_precision: 0.5143620574482298, overall_recall: 0.3078768492602959, overall_f1: 0.38519259629814906, overall_accuracy: 0.7880065756557787
Finish training, best metric: 
{'APL_precision': 0.4636363636363636, 'APL_recall': 0.3, 'APL_f1': 0.3642857142857142, 'APL_number': 170, 'CMT_precision': 0.5337837837837838, 'CMT_recall': 0.40512820512820513, 'CMT_f1': 0.4606413994169096, 'CMT_number': 195, 'DSC_precision': 0.5063291139240507, 'DSC_recall': 0.2745995423340961, 'DSC_f1': 0.3560830860534125, 'DSC_number': 437, 'MAT_precision': 0.5461309523809523, 'MAT_recall': 0.5381231671554252, 'MAT_f1': 0.5420974889217134, 'MAT_number': 682, 'PRO_precision': 0.5659340659340659, 'PRO_recall': 0.13359273670557717, 'PRO_f1': 0.2161594963273872, 'PRO_number': 771, 'SMT_precision': 0.25555555555555554, 'SMT_recall': 0.13450292397660818, 'SMT_f1': 0.17624521072796934, 'SMT_number': 171, 'SPL_precision': 0.46551724137931033, 'SPL_recall': 0.36, 'SPL_f1': 0.40601503759398494, 'SPL_number': 75, 'overall_precision': 0.5143620574482298, 'overall_recall': 0.3078768492602959, 'overall_f1': 0.38519259629814906, 'overall_accuracy': 0.7880065756557787}
